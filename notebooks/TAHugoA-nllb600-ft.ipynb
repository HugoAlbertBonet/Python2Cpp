{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10087360,"sourceType":"datasetVersion","datasetId":6219636},{"sourceId":10098879,"sourceType":"datasetVersion","datasetId":6228461}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LLaMa tuto","metadata":{}},{"cell_type":"code","source":"!pip install datasets evaluate transformers==4.33.1 accelerate peft bitsandbytes --quiet\n!pip install sacrebleu --quiet\n!pip install huggingface_hub --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:11:23.869175Z","iopub.execute_input":"2024-12-09T10:11:23.869488Z","iopub.status.idle":"2024-12-09T10:12:02.314504Z","shell.execute_reply.started":"2024-12-09T10:11:23.869452Z","shell.execute_reply":"2024-12-09T10:12:02.313305Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from datasets import ClassLabel\nfrom datasets import Dataset, DatasetDict\nimport pandas as pd\nimport re\n\ndef retrieve_dataset(split:[\"train\", \"val\", \"test\"] = \"train\", dest_lang:[\"py\", \"cpp\", \"both\"] = \"cpp\") -> Dataset:\n    \"\"\"\n    Retrieves a dataset of dictionaries with the codification:\n        {\"id\": id, \n        \"translation\":\n            {\"py\":pycode, \n            \"cpp\":cppcode}}\n    According to the split selected\n    \"\"\"\n\n    #Load the files\n    with open(f\"/kaggle/input/snippets/C++-Python/{split}-C++-map.jsonl\", \"r\") as f: cppids = f.read()\n    with open(f\"/kaggle/input/snippets/C++-Python/{split}-Python-map.jsonl\", \"r\") as f: pyids = f.read()\n    with open(f\"/kaggle/input/snippets/C++-Python/{split}-C++-Python-tok.cpp\", \"r\") as f: cppcode = f.read()\n    with open(f\"/kaggle/input/snippets/C++-Python/{split}-C++-Python-tok.py\", \"r\") as f: pycode = f.read()\n\n    #Divide the text\n    pyids = pyids.replace(\"Python\", \"py\"); pyids = re.findall(r\"(\\d+)-(py)-(\\d+)\", pyids)\n    cppids = cppids.replace(\"C++\", \"cpp\"); cppids = re.findall(r\"(\\d+)-(cpp)-(\\d+)\", cppids)\n    pycode = pycode.split(\"\\n\")[:-1]\n    cppcode = cppcode.split(\"\\n\")[:-1]\n\n    assert len(pycode) == len(pyids) and len(cppcode) == len(cppids) #Ids and lines of code are of equal length\n\n    ids = []\n    for i, lang, j in pyids:\n        if i not in ids:\n            ids.append(i)\n    \n    assert all(i in ids for i, lang, j in cppids) #Same ids for cpp and py\n\n    #Create list of dicts with the desired codification\n    idpy, idcpp = 0, 0\n    dataset = []\n    \n    for i in ids:\n        dic = {\"source_text\": \"\", \"dest_text\": \"\", \"dest_lang\": \"\"}\n        pytrans, cpptrans = pycode[idpy], cppcode[idcpp]\n        idpy += 1; idcpp += 1\n        while idpy < len(pyids) and i in pyids[idpy]:\n            pytrans += \"\\n\" + pycode[idpy]\n            idpy += 1\n        while idcpp < len(cppids) and i in cppids[idcpp]:\n            cpptrans += \"\\n\" + cppcode[idcpp]\n            idcpp += 1\n\n        if dest_lang == \"cpp\" or dest_lang == \"both\":\n            dic[\"source_text\"]= pytrans\n            dic[\"dest_text\"] = cpptrans\n            dic[\"dest_lang\"] = \"cpp\"\n            dataset.append(dic)\n        if dest_lang == \"both\":\n            dic = {\"source_text\": \"\", \"dest_text\": \"\", \"dest_lang\": \"\"}\n        if dest_lang == \"py\" or dest_lang == \"both\":\n            dic[\"source_text\"]= cpptrans\n            dic[\"dest_text\"] = pytrans\n            dic[\"dest_lang\"] = \"py\"\n            dataset.append(dic)\n\n\n    #Create the final dataset\n    split_ds = Dataset.from_pandas(pd.DataFrame(data=dataset))\n    return split_ds\n\n\ndef retrieve_all() -> DatasetDict:\n    \"\"\"\n    Retrieves a DatasetDict of Datasets cointaining the data of each split\n    \"\"\"\n    \n    train_ds = retrieve_dataset()\n    val_ds = retrieve_dataset(\"val\")\n    test_ds = retrieve_dataset(\"test\")\n    ds = DatasetDict({\"train\": train_ds, \"validation\": val_ds, \"test\": test_ds})\n    return ds.class_encode_column(\"dest_lang\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:12:02.317618Z","iopub.execute_input":"2024-12-09T10:12:02.318006Z","iopub.status.idle":"2024-12-09T10:12:03.475622Z","shell.execute_reply.started":"2024-12-09T10:12:02.317966Z","shell.execute_reply":"2024-12-09T10:12:03.474820Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"ds = retrieve_all()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:12:03.476655Z","iopub.execute_input":"2024-12-09T10:12:03.476998Z","iopub.status.idle":"2024-12-09T10:12:20.534672Z","shell.execute_reply.started":"2024-12-09T10:12:03.476971Z","shell.execute_reply":"2024-12-09T10:12:20.533850Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Casting to class labels:   0%|          | 0/9308 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a26d1ec83ee49e193266c415631e2d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting to class labels:   0%|          | 0/477 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e97d5dd5a484adab1bf882af0adb601"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting to class labels:   0%|          | 0/890 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"033d175c9adb4a7a966d50135dab480a"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"ds[\"train\"].features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T16:05:16.254313Z","iopub.execute_input":"2024-12-05T16:05:16.254577Z","iopub.status.idle":"2024-12-05T16:05:16.260765Z","shell.execute_reply.started":"2024-12-05T16:05:16.254551Z","shell.execute_reply":"2024-12-05T16:05:16.259923Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'source_text': Value(dtype='string', id=None),\n 'dest_text': Value(dtype='string', id=None),\n 'dest_lang': ClassLabel(names=['cpp'], id=None)}"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:12:20.535999Z","iopub.execute_input":"2024-12-09T10:12:20.536363Z","iopub.status.idle":"2024-12-09T10:12:21.921598Z","shell.execute_reply.started":"2024-12-09T10:12:20.536335Z","shell.execute_reply":"2024-12-09T10:12:21.920568Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmax_tok_length = 128\n#checkpoint = \"meta-llama/Llama-2-7b-hf\"\ncheckpoint = \"codellama/CodeLlama-7b-hf\" \n#checkpoint = \"ajibawa-2023/Code-Llama-3-8B\"\ntokenizer = AutoTokenizer.from_pretrained(\n    checkpoint, use_auth_token=True,\n    padding=True,\n    pad_to_multiple_of=8,\n    truncation=True,\n    max_tok_len=max_tok_length,\n    padding_side='left',\n    )\ntokenizer.pad_token = \"[PAD]\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:12:21.923140Z","iopub.execute_input":"2024-12-09T10:12:21.923447Z","iopub.status.idle":"2024-12-09T10:12:24.656240Z","shell.execute_reply.started":"2024-12-09T10:12:21.923420Z","shell.execute_reply":"2024-12-09T10:12:24.655344Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:640: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/749 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56eba8c247734646a185770c9bdca8bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ae08566a6bf420abb37431cc6da9ac5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"600b799db8924b918cf9b5e544341bbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cdb08cbd5524eccbf39abf725c2931d"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def preprocess_function(sample):\n    model_inputs = tokenizer(\n        sample[\"source_text\"], \n        text_target = sample[\"dest_text\"],\n        )\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:12:24.657326Z","iopub.execute_input":"2024-12-09T10:12:24.657739Z","iopub.status.idle":"2024-12-09T10:12:24.661994Z","shell.execute_reply.started":"2024-12-09T10:12:24.657711Z","shell.execute_reply":"2024-12-09T10:12:24.661210Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"tokenized_ds = ds.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:12:24.668559Z","iopub.execute_input":"2024-12-09T10:12:24.668874Z","iopub.status.idle":"2024-12-09T10:12:30.319202Z","shell.execute_reply.started":"2024-12-09T10:12:24.668837Z","shell.execute_reply":"2024-12-09T10:12:30.318469Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9308 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50f5f0f3143f47d6a8dc5b6855f7d02d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/477 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7d5b07944de44b28a9a837e21a4ea2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/890 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b03c723d6b924060a854089026706db5"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T17:11:08.682837Z","iopub.execute_input":"2024-12-06T17:11:08.683636Z","iopub.status.idle":"2024-12-06T17:11:08.689314Z","shell.execute_reply.started":"2024-12-06T17:11:08.683601Z","shell.execute_reply":"2024-12-06T17:11:08.688531Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['source_text', 'dest_text', 'dest_lang'],\n        num_rows: 9308\n    })\n    validation: Dataset({\n        features: ['source_text', 'dest_text', 'dest_lang'],\n        num_rows: 477\n    })\n    test: Dataset({\n        features: ['source_text', 'dest_text', 'dest_lang'],\n        num_rows: 890\n    })\n})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"tokenized_ds = tokenized_ds.filter(lambda x: len(x[\"input_ids\"]) <= max_tok_length and len(x[\"labels\"]) <= max_tok_length , desc=f\"Discarding source and target sentences with more than {max_tok_length} tokens\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:12:30.320172Z","iopub.execute_input":"2024-12-09T10:12:30.320446Z","iopub.status.idle":"2024-12-09T10:12:33.587498Z","shell.execute_reply.started":"2024-12-09T10:12:30.320420Z","shell.execute_reply":"2024-12-09T10:12:33.586654Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Discarding source and target sentences with more than 128 tokens:   0%|          | 0/9308 [00:00<?, ? examples…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9af328eda1e41aea06327841306fe7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Discarding source and target sentences with more than 128 tokens:   0%|          | 0/477 [00:00<?, ? examples/…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33e86876792f4446b4bb4e70ba219c28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Discarding source and target sentences with more than 128 tokens:   0%|          | 0/890 [00:00<?, ? examples/…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bb5cfae25b4475fa00f164b6005f6e4"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"tokenized_ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T11:51:22.549625Z","iopub.execute_input":"2024-12-07T11:51:22.549875Z","iopub.status.idle":"2024-12-07T11:51:22.555739Z","shell.execute_reply.started":"2024-12-07T11:51:22.549851Z","shell.execute_reply":"2024-12-07T11:51:22.554889Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['source_text', 'dest_text', 'dest_lang', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 1079\n    })\n    validation: Dataset({\n        features: ['source_text', 'dest_text', 'dest_lang', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 56\n    })\n    test: Dataset({\n        features: ['source_text', 'dest_text', 'dest_lang', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 133\n    })\n})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"dic = []\nfor sample in tokenized_ds['train']:\n    sample_length = len(sample['input_ids'])\n    dic.append(sample_length)\n\nimport pandas as pd\ndf = pd.DataFrame({\"length\":dic})\ndf.hist(bins = 100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:12:33.588776Z","iopub.execute_input":"2024-12-09T10:12:33.589540Z","iopub.status.idle":"2024-12-09T10:12:34.180697Z","shell.execute_reply.started":"2024-12-09T10:12:33.589499Z","shell.execute_reply":"2024-12-09T10:12:34.179921Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"array([[<Axes: title={'center': 'length'}>]], dtype=object)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import torch\n\nsrc = \"py\"\ntgt = \"cpp\"\ntask_prefix = f\"Translate from {src} to {tgt}:\\n\"\ns = \"\"\n\n\nif \"Llama-3\" in checkpoint: tokenizer.pad_token_id = 128002 \n\nprefix_tok_len = len(tokenizer.encode(f\"{task_prefix}{src}: {s} = {tgt}: \"))\nmax_tok_len = prefix_tok_len\n# Adding 2 for new line in target sentence and eos_token_id token\nmax_tok_len += 2 * max_tok_length + 2\n\n\ndef preprocess4training_function(sample):\n    \n    sample_size = len(sample[\"source_text\"])\n\n    # Creating the prompt with the task description for each source sentence\n    inputs  = [f\"{task_prefix}{src}: {s} = {tgt}: \" for s in sample[\"source_text\"]]\n\n    # Appending new line after each sample in the batch\n    targets = [f\"{s}\\n\" for s in sample[\"dest_text\"]]\n\n    # Applying the Llama2 tokenizer to the inputs and targets \n    # to obtain \"input_ids\" (token_ids) and \"attention mask\" \n    model_inputs = tokenizer(inputs)\n    labels = tokenizer(targets)\n    \n    # Each input is appended with its target \n    # Each target is prepended with as many special token id (-100) as the original input length\n    # Both input and target (label) has the same max_tok_len\n    # Attention mask is all 1s \n    for i in range(sample_size):\n        sample_input_ids = model_inputs[\"input_ids\"][i]\n        label_input_ids = labels[\"input_ids\"][i] + [tokenizer.eos_token_id]\n        model_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n        labels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n        model_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n\n    # Each input is applied left padding up to max_tok_len\n    # Attention mask is 0 for padding\n    # Each target (label) is left filled with special token id (-100)\n    # Finally inputs, attention_mask and targets (labels) are truncated to max_tok_len\n    for i in range(sample_size):\n        sample_input_ids = model_inputs[\"input_ids\"][i]\n        label_input_ids = labels[\"input_ids\"][i]\n        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n            max_tok_len - len(sample_input_ids)\n        ) + sample_input_ids\n        model_inputs[\"attention_mask\"][i] = [0] * (max_tok_len - len(sample_input_ids)) + model_inputs[\n            \"attention_mask\"\n        ][i]\n        labels[\"input_ids\"][i] = [-100] * (max_tok_len - len(sample_input_ids)) + label_input_ids\n        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_tok_len])\n        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_tok_len])\n        labels[\"input_ids\"][i] = torch.tensor(labels[\"input_ids\"][i][:max_tok_len])\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:12:34.181795Z","iopub.execute_input":"2024-12-09T10:12:34.182128Z","iopub.status.idle":"2024-12-09T10:12:37.173960Z","shell.execute_reply.started":"2024-12-09T10:12:34.182091Z","shell.execute_reply":"2024-12-09T10:12:37.173302Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def preprocess4test_function(sample):\n    inputs = [f\"{task_prefix}{src}: {s} = {tgt}: \" for s in sample[\"source_text\"]]\n    model_inputs = tokenizer(inputs,padding=True,)\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:12:37.175087Z","iopub.execute_input":"2024-12-09T10:12:37.175455Z","iopub.status.idle":"2024-12-09T10:12:37.179772Z","shell.execute_reply.started":"2024-12-09T10:12:37.175408Z","shell.execute_reply":"2024-12-09T10:12:37.178760Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"preprocessed_train_dataset = tokenized_ds['train'].map(preprocess4training_function, batched=True)\npreprocessed_dev_dataset = tokenized_ds['validation'].map(preprocess4training_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:12:37.180942Z","iopub.execute_input":"2024-12-09T10:12:37.181352Z","iopub.status.idle":"2024-12-09T10:12:37.892485Z","shell.execute_reply.started":"2024-12-09T10:12:37.181316Z","shell.execute_reply":"2024-12-09T10:12:37.891637Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1079 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0201ade4e71944d68a25531626b0c077"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/56 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98d219f1328041e099f33c24219e61b6"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"preprocessed_test_dataset = tokenized_ds['test'].map(preprocess4test_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:12:37.893730Z","iopub.execute_input":"2024-12-09T10:12:37.894083Z","iopub.status.idle":"2024-12-09T10:12:37.957966Z","shell.execute_reply.started":"2024-12-09T10:12:37.894045Z","shell.execute_reply":"2024-12-09T10:12:37.957211Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/133 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bd00c05d9f24a51896f58a6daf6153c"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig\n\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=torch.bfloat16,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:12:37.959328Z","iopub.execute_input":"2024-12-09T10:12:37.959665Z","iopub.status.idle":"2024-12-09T10:12:37.967598Z","shell.execute_reply.started":"2024-12-09T10:12:37.959620Z","shell.execute_reply":"2024-12-09T10:12:37.966799Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    checkpoint,\n    quantization_config=quantization_config,\n    torch_dtype=torch.bfloat16,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:12:37.968535Z","iopub.execute_input":"2024-12-09T10:12:37.968776Z","iopub.status.idle":"2024-12-09T10:14:05.017569Z","shell.execute_reply.started":"2024-12-09T10:12:37.968753Z","shell.execute_reply":"2024-12-09T10:14:05.016881Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/637 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07a002aaaa48454abd3c3312c0447b63"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"417aca89f2ef408e8cbe5bf910a0360b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"914b4dc3772241f6ab031a2c1412e35a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"371a731ffa1c462188952d8d2ba80070"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6468abc4d6bf41a4a0430fb47f028f48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4900c22383794214a584f4e43612150d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"306bbba32265428cbd5f1dc375761dce"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"!pip install peft==0.13 --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:14:05.018503Z","iopub.execute_input":"2024-12-09T10:14:05.018986Z","iopub.status.idle":"2024-12-09T10:14:16.266887Z","shell.execute_reply.started":"2024-12-09T10:14:05.018959Z","shell.execute_reply":"2024-12-09T10:14:16.265971Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from peft import prepare_model_for_kbit_training\n\nmodel = prepare_model_for_kbit_training(model, use_gradient_checkpointing=False, gradient_checkpointing_kwargs={'use_reentrant':False})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:14:16.268267Z","iopub.execute_input":"2024-12-09T10:14:16.268568Z","iopub.status.idle":"2024-12-09T10:14:16.363655Z","shell.execute_reply.started":"2024-12-09T10:14:16.268540Z","shell.execute_reply":"2024-12-09T10:14:16.363027Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\nconfig = LoraConfig(\n    task_type=\"CAUSAL_LM\",\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    inference_mode=False,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:14:16.364529Z","iopub.execute_input":"2024-12-09T10:14:16.364743Z","iopub.status.idle":"2024-12-09T10:14:16.368838Z","shell.execute_reply.started":"2024-12-09T10:14:16.364721Z","shell.execute_reply":"2024-12-09T10:14:16.367925Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"lora_model = get_peft_model(model, config)\nlora_model.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:14:16.369947Z","iopub.execute_input":"2024-12-09T10:14:16.370357Z","iopub.status.idle":"2024-12-09T10:14:16.562481Z","shell.execute_reply.started":"2024-12-09T10:14:16.370320Z","shell.execute_reply":"2024-12-09T10:14:16.561646Z"}},"outputs":[{"name":"stdout","text":"trainable params: 8,388,608 || all params: 6,746,935,296 || trainable%: 0.1243\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False, pad_to_multiple_of=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:14:16.563438Z","iopub.execute_input":"2024-12-09T10:14:16.563727Z","iopub.status.idle":"2024-12-09T10:14:17.222289Z","shell.execute_reply.started":"2024-12-09T10:14:16.563698Z","shell.execute_reply":"2024-12-09T10:14:17.221375Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nbatch_size = 1\ngradient_accumulation_steps = 8\nmodel_name = checkpoint.split(\"/\")[-1]\nargs = TrainingArguments(\n    f\"{model_name}-finetuned-py-to-cpp\",\n    evaluation_strategy = \"epoch\",\n    learning_rate=1e-4,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    save_total_limit=2,\n    num_train_epochs=3,\n    warmup_steps=100,\n    optim=\"adamw_bnb_8bit\",\n    prediction_loss_only=True,\n    gradient_accumulation_steps = gradient_accumulation_steps,\n    fp16=True,\n    group_by_length=True,\n    push_to_hub=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:14:17.228055Z","iopub.execute_input":"2024-12-09T10:14:17.229528Z","iopub.status.idle":"2024-12-09T10:14:17.266597Z","shell.execute_reply.started":"2024-12-09T10:14:17.229484Z","shell.execute_reply":"2024-12-09T10:14:17.265783Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    lora_model,\n    args,\n    train_dataset=preprocessed_train_dataset,\n    eval_dataset=preprocessed_dev_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:14:17.267734Z","iopub.execute_input":"2024-12-09T10:14:17.268187Z","iopub.status.idle":"2024-12-09T10:14:18.184686Z","shell.execute_reply.started":"2024-12-09T10:14:17.268130Z","shell.execute_reply":"2024-12-09T10:14:18.184023Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:457: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T10:14:18.185653Z","iopub.execute_input":"2024-12-09T10:14:18.185925Z","iopub.status.idle":"2024-12-09T13:54:00.910765Z","shell.execute_reply.started":"2024-12-09T10:14:18.185898Z","shell.execute_reply":"2024-12-09T13:54:00.910012Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112663811110856, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ace8abd5183243e28d0d4f2731ad27b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241209_101429-cjtwp2iu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/hyperloopupv/huggingface/runs/cjtwp2iu' target=\"_blank\">worldly-lake-29</a></strong> to <a href='https://wandb.ai/hyperloopupv/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/hyperloopupv/huggingface' target=\"_blank\">https://wandb.ai/hyperloopupv/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/hyperloopupv/huggingface/runs/cjtwp2iu' target=\"_blank\">https://wandb.ai/hyperloopupv/huggingface/runs/cjtwp2iu</a>"},"metadata":{}},{"name":"stderr","text":"You're using a CodeLlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='201' max='201' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [201/201 3:38:36, Epoch 2/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>No log</td>\n      <td>0.836617</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.416990</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.387790</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=201, training_loss=0.7329443936324238, metrics={'train_runtime': 13181.6297, 'train_samples_per_second': 0.246, 'train_steps_per_second': 0.015, 'total_flos': 1.823847204716544e+16, 'train_loss': 0.7329443936324238, 'epoch': 2.98})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"trainer.push_to_hub(commit_message=\"Training complete\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T13:54:00.912007Z","iopub.execute_input":"2024-12-09T13:54:00.913020Z","iopub.status.idle":"2024-12-09T13:54:05.662099Z","shell.execute_reply.started":"2024-12-09T13:54:00.912977Z","shell.execute_reply":"2024-12-09T13:54:05.661278Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a0f1c03c5314af791d4c2ac97baf7f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d977eabe25a2403aaaa4a3b133a7d78e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.bin:   0%|          | 0.00/33.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7570afb9365740328b91ee2dce6f0cc2"}},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/hugo-albert/CodeLlama-7b-hf-finetuned-py-to-cpp/commit/e8b734088b34c24b0249abf4c8f9d49b9b9178e9', commit_message='Training complete', commit_description='', oid='e8b734088b34c24b0249abf4c8f9d49b9b9178e9', pr_url=None, repo_url=RepoUrl('https://huggingface.co/hugo-albert/CodeLlama-7b-hf-finetuned-py-to-cpp', endpoint='https://huggingface.co', repo_type='model', repo_id='hugo-albert/CodeLlama-7b-hf-finetuned-py-to-cpp'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"from transformers import GenerationConfig\n\ngeneration_config = GenerationConfig.from_pretrained(\n    checkpoint,\n)\n\nprint(generation_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T13:54:05.663132Z","iopub.execute_input":"2024-12-09T13:54:05.663428Z","iopub.status.idle":"2024-12-09T13:54:05.761062Z","shell.execute_reply.started":"2024-12-09T13:54:05.663397Z","shell.execute_reply":"2024-12-09T13:54:05.760316Z"}},"outputs":[{"name":"stdout","text":"GenerationConfig {\n  \"_from_model_config\": true,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"transformers_version\": \"4.33.1\"\n}\n\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"test_batch_size = 4\nbatch_tokenized_test = preprocessed_test_dataset.batch(test_batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T13:54:05.761915Z","iopub.execute_input":"2024-12-09T13:54:05.762117Z","iopub.status.idle":"2024-12-09T13:54:05.858051Z","shell.execute_reply.started":"2024-12-09T13:54:05.762095Z","shell.execute_reply":"2024-12-09T13:54:05.857291Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batching examples:   0%|          | 0/133 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf3fc75c565e4ba49d2c9c2116471a60"}},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"number_of_batches = len(batch_tokenized_test[\"input_ids\"])\noutput_sequences = []\nfor i in range(number_of_batches):\n    output_batch = lora_model.generate(\n        generation_config=generation_config, \n        input_ids=torch.tensor(batch_tokenized_test[\"input_ids\"][i]).cuda(), \n        attention_mask=torch.tensor(batch_tokenized_test[\"attention_mask\"][i]).cuda(), \n        max_length = max_tok_len, \n        num_beams=1, \n        do_sample=False,)\n    output_sequences.extend(output_batch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T13:54:05.859025Z","iopub.execute_input":"2024-12-09T13:54:05.859289Z","iopub.status.idle":"2024-12-09T14:25:54.942890Z","shell.execute_reply.started":"2024-12-09T13:54:05.859265Z","shell.execute_reply":"2024-12-09T14:25:54.942179Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"!pip install unbabel-comet --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T14:25:54.944125Z","iopub.execute_input":"2024-12-09T14:25:54.944773Z","iopub.status.idle":"2024-12-09T14:26:05.924253Z","shell.execute_reply.started":"2024-12-09T14:25:54.944731Z","shell.execute_reply":"2024-12-09T14:26:05.923469Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.5 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 4.25.5 which is incompatible.\ngoogle-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.5 which is incompatible.\ngoogle-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 4.25.5 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.5 which is incompatible.\nkfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.5 which is incompatible.\ntensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.5 which is incompatible.\ntensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"from evaluate import load\n\ncomet = load(\"comet\")\nbleu = load(\"sacrebleu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T14:26:05.925751Z","iopub.execute_input":"2024-12-09T14:26:05.926043Z","iopub.status.idle":"2024-12-09T14:26:37.646112Z","shell.execute_reply.started":"2024-12-09T14:26:05.926015Z","shell.execute_reply":"2024-12-09T14:26:37.645221Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.97k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4571b6f63be44496af92b1c5462b4ef1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d15c8e308af4db7860f56ae9b41fc18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/3.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c407d0e67a14ea6aa48e5ef52f6014f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f61ffacda83844d6b3e83b01a9d18f4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"hparams.yaml:   0%|          | 0.00/567 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd02da0a6f92474aa122401393891519"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"LICENSE:   0%|          | 0.00/9.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49f8736922f14f368fce5f5b7b835cb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.ckpt:   0%|          | 0.00/2.32G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d872f83e39064741987ef8d80dfabe16"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f5709f804f74cecad8d3e6b47e92bbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fe49a3c451a4db982b4acfb824a16b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2261056b307c40ac9979ee758860c939"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73648a7804f5445a9d748788910433f7"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0ce7bfc0f964987b4f7584d1ee9f4fd"}},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"import re\n\ndef compute_metrics(sample, output_sequences):\n    inputs = [f\"{task_prefix}{src}: {s} = {tgt}: \"  for s in sample[\"source_text\"]]\n    preds = tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n    #print(inputs)\n    #print(preds)\n    for i, (input,pred) in enumerate(zip(inputs,preds)):\n      pred = re.search(r'^.*\\n',pred.removeprefix(input).lstrip())\n      if pred is not None:\n        preds[i] = pred.group()[:-1]\n      else:\n        preds[i] = \"\"\n    #print(sample[\"source_text\"])\n    #print(sample[\"dest_text\"])\n    #print(preds)\n    resultcomet = comet.compute(sources = sample[\"source_text\"], predictions=preds, references=sample[\"dest_text\"])\n    resultbleu = bleu.compute(predictions=preds, references=sample[\"dest_text\"])\n    result = {\"bleu\": resultbleu[\"score\"], \"comet\": resultcomet[\"mean_score\"], \"comet_all\": resultcomet[\"scores\"]}\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T14:26:37.647330Z","iopub.execute_input":"2024-12-09T14:26:37.648253Z","iopub.status.idle":"2024-12-09T14:26:37.655437Z","shell.execute_reply.started":"2024-12-09T14:26:37.648211Z","shell.execute_reply":"2024-12-09T14:26:37.654492Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"result = compute_metrics(preprocessed_test_dataset,output_sequences)\nprint(f'BLEU score: {result[\"bleu\"]}')\nprint(f'COMET score: {result[\"comet\"]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T14:26:37.656348Z","iopub.execute_input":"2024-12-09T14:26:37.656585Z","iopub.status.idle":"2024-12-09T14:26:49.989125Z","shell.execute_reply.started":"2024-12-09T14:26:37.656561Z","shell.execute_reply":"2024-12-09T14:26:49.988210Z"}},"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"BLEU score: 2.413789323551916\nCOMET score: 0.5751606332404273\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(result[\"comet_all\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T14:26:49.990732Z","iopub.execute_input":"2024-12-09T14:26:49.991647Z","iopub.status.idle":"2024-12-09T14:26:50.252232Z","shell.execute_reply.started":"2024-12-09T14:26:49.991599Z","shell.execute_reply":"2024-12-09T14:26:50.251343Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"(array([34.,  0.,  4., 16., 13., 15.,  7., 10., 14., 20.]),\n array([0.22804706, 0.29889135, 0.36973565, 0.44057994, 0.51142423,\n        0.58226853, 0.65311282, 0.72395712, 0.79480141, 0.86564571,\n        0.93649   ]),\n <BarContainer object of 10 artists>)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"def check_translation(i):\n    print(f\"COMET of snippet {i}:\", result[\"comet_all\"][i])\n    print(\"REAL: \\n\", preprocessed_test_dataset[i][\"dest_text\"].replace(\"NEW_LINE\", \"\\n\"))\n    print(\"PRED: \\n\", tokenizer.batch_decode(output_sequences, skip_special_tokens=True)[i].replace(\"NEW_LINE\", \"\\n\").split(\"= cpp: \")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T14:26:50.253275Z","iopub.execute_input":"2024-12-09T14:26:50.253533Z","iopub.status.idle":"2024-12-09T14:26:50.259090Z","shell.execute_reply.started":"2024-12-09T14:26:50.253507Z","shell.execute_reply":"2024-12-09T14:26:50.258316Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"for i in range(len(result[\"comet_all\"])):\n    if result[\"comet_all\"][i] > 0.75:\n        check_translation(i)\n        break\n\nprint(\"===================\")\nfor i in range(len(result[\"comet_all\"])):\n    if result[\"comet_all\"][i] < 0.3:\n        check_translation(i)\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T14:26:50.260252Z","iopub.execute_input":"2024-12-09T14:26:50.260596Z","iopub.status.idle":"2024-12-09T14:26:50.323063Z","shell.execute_reply.started":"2024-12-09T14:26:50.260549Z","shell.execute_reply":"2024-12-09T14:26:50.322254Z"}},"outputs":[{"name":"stdout","text":"COMET of snippet 0: 0.8800185322761536\nREAL: \n void checkSolution ( int a , int b , int c ) { if ( a == c ) cout << \" Yes \" ; else cout << \" No \" ; }\nint main ( ) { int a = 2 , b = 0 , c = 2 ; checkSolution ( a , b , c ) ; return 0 ; }\nPRED: \n  void checkSolution ( int a , int b , int c ) { if ( a == c ) cout << \" Yes \" ; else cout << \" No \" ; }\nint main ( ) { int a = 2 , b = 0 , c = 2 ; checkSolution ( a , b , c ) ; return 0 ; }\n\n===================\nCOMET of snippet 1: 0.25628820061683655\nREAL: \n void printKNumbers ( int N , int K ) {\nfor ( int i = 0 ; i < K - 1 ; i ++ ) cout << 1 << \" ▁ \" ;\ncout << ( N - K + 1 ) ; }\nint main ( ) { int N = 10 , K = 3 ; printKNumbers ( N , K ) ; return 0 ; }\nPRED: \n  void printKNumbers ( int N , int K ) {\nfor ( int i = 0 ; i < K - 1 ; i ++ ) cout << 1 << \"   \" ;\ncout << N - K + 1 ; }\nint main ( ) { int N = 10 , K = 3 ; printKNumbers ( N , K ) ; return 0 ; }\n\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"# HF tuto","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict\nimport pandas as pd\nimport re\n\ndef retrieve_dataset(split:[\"train\", \"val\", \"test\"] = \"train\") -> Dataset:\n    \"\"\"\n    Retrieves a dataset of dictionaries with the codification:\n        {\"id\": id, \n        \"translation\":\n            {\"py\":pycode, \n            \"cpp\":cppcode}}\n    According to the split selected\n    \"\"\"\n\n    #Load the files\n    with open(f\"/kaggle/input/snippets/C++-Python/{split}-C++-map.jsonl\", \"r\") as f: cppids = f.read()\n    with open(f\"/kaggle/input/snippets/C++-Python/{split}-Python-map.jsonl\", \"r\") as f: pyids = f.read()\n    with open(f\"/kaggle/input/snippets/C++-Python/{split}-C++-Python-tok.cpp\", \"r\") as f: cppcode = f.read()\n    with open(f\"/kaggle/input/snippets/C++-Python/{split}-C++-Python-tok.py\", \"r\") as f: pycode = f.read()\n\n    #Divide the text\n    pyids = pyids.replace(\"Python\", \"py\"); pyids = re.findall(r\"(\\d+)-(py)-(\\d+)\", pyids)\n    cppids = cppids.replace(\"C++\", \"cpp\"); cppids = re.findall(r\"(\\d+)-(cpp)-(\\d+)\", cppids)\n    pycode = pycode.split(\"\\n\")[:-1]\n    cppcode = cppcode.split(\"\\n\")[:-1]\n\n    assert len(pycode) == len(pyids) and len(cppcode) == len(cppids) #Ids and lines of code are of equal length\n\n    ids = []\n    for i, lang, j in pyids:\n        if i not in ids:\n            ids.append(i)\n    \n    assert all(i in ids for i, lang, j in cppids) #Same ids for cpp and py\n\n    #Create list of dicts with the desired codification\n    idpy, idcpp = 0, 0\n    dataset = []\n    \n    for i in ids:\n        dic = {\"id\": i, \"translation\": {}}\n        pytrans, cpptrans = pycode[idpy], cppcode[idcpp]\n        idpy += 1; idcpp += 1\n        while idpy < len(pyids) and i in pyids[idpy]:\n            pytrans += \"\\n\" + pycode[idpy]\n            idpy += 1\n        while idcpp < len(cppids) and i in cppids[idcpp]:\n            cpptrans += \"\\n\" + cppcode[idcpp]\n            idcpp += 1\n    \n        dic[\"translation\"][\"py\"] = pytrans\n        dic[\"translation\"][\"cpp\"] = cpptrans\n        dataset.append(dic)\n\n\n    #Create the final dataset\n    split_ds = Dataset.from_pandas(pd.DataFrame(data=dataset))\n    return split_ds\n\n\ndef retrieve_all() -> DatasetDict:\n    \"\"\"\n    Retrieves a DatasetDict of Datasets cointaining the data of each split\n    \"\"\"\n    \n    train_ds = retrieve_dataset()\n    val_ds = retrieve_dataset(\"val\")\n    test_ds = retrieve_dataset(\"test\")\n    ds = DatasetDict({\"train\": train_ds, \"validation\": val_ds, \"test\": test_ds})\n    return ds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ds = retrieve_all()\nds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T10:51:30.760175Z","iopub.execute_input":"2024-12-05T10:51:30.761066Z","iopub.status.idle":"2024-12-05T10:51:32.149104Z","shell.execute_reply.started":"2024-12-05T10:51:30.761030Z","shell.execute_reply":"2024-12-05T10:51:32.148124Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ncheckpoint = \"google-t5/t5-small\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T10:51:33.124162Z","iopub.execute_input":"2024-12-05T10:51:33.125120Z","iopub.status.idle":"2024-12-05T10:51:39.025542Z","shell.execute_reply.started":"2024-12-05T10:51:33.125083Z","shell.execute_reply":"2024-12-05T10:51:39.024830Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f06a875e67d4f2c808e0d9ed42d0c90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a65809c92e4b457f88a47540ca9a87c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fbf102220b6423ab1785a8b6f8cc75e"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"source_lang = \"py\"\ntarget_lang = \"cpp\"\nprefix = \"translate Python to C++: \"\n\n\ndef preprocess_function(examples):\n    inputs = [prefix + example[source_lang] for example in examples[\"translation\"]]\n    targets = [example[target_lang] for example in examples[\"translation\"]]\n    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T10:51:39.026968Z","iopub.execute_input":"2024-12-05T10:51:39.027410Z","iopub.status.idle":"2024-12-05T10:51:39.032348Z","shell.execute_reply.started":"2024-12-05T10:51:39.027382Z","shell.execute_reply":"2024-12-05T10:51:39.031482Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"tokenized_ds = ds.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T10:51:39.033459Z","iopub.execute_input":"2024-12-05T10:51:39.033814Z","iopub.status.idle":"2024-12-05T10:51:46.627047Z","shell.execute_reply.started":"2024-12-05T10:51:39.033782Z","shell.execute_reply":"2024-12-05T10:51:46.626034Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9308 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55a9de2602604ed1ac9a135faf5799ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/477 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4ccb9f7872944ff92d610fe501c5c4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/890 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bce4728adf784c36826ab92f7cb27352"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T10:51:46.629289Z","iopub.execute_input":"2024-12-05T10:51:46.629893Z","iopub.status.idle":"2024-12-05T10:51:59.937920Z","shell.execute_reply.started":"2024-12-05T10:51:46.629851Z","shell.execute_reply":"2024-12-05T10:51:59.937200Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"!pip install evaluate sacrebleu unbabel-comet --quiet\nimport evaluate\n\nmetric = evaluate.load(\"sacrebleu\")\ncomet = load(\"comet\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T17:01:15.205910Z","iopub.execute_input":"2024-12-10T17:01:15.206335Z","iopub.status.idle":"2024-12-10T17:01:56.876651Z","shell.execute_reply.started":"2024-12-10T17:01:15.206299Z","shell.execute_reply":"2024-12-10T17:01:56.875654Z"}},"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.5 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 4.25.5 which is incompatible.\ngoogle-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.5 which is incompatible.\ngoogle-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 4.25.5 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.5 which is incompatible.\nkfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.5 which is incompatible.\ntensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.5 which is incompatible.\ntensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85d131f93740455fa4180a2431c58126"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"950c0d02a9c644b689499c11737b1dfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"hparams.yaml:   0%|          | 0.00/567 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3065b6e919b416c87a5f978e7abd6ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"LICENSE:   0%|          | 0.00/9.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8d5a282f0b14664ab73f3366cf1cfca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/3.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"230bada08942407e856ec68034f82158"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.ckpt:   0%|          | 0.00/2.32G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c4f05e899f541edb7f313e2729464ea"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4c61106c7484389bb2696bc7df82b5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20fb7917066f4443a224943ed91f2cd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ff5a04bb765438cba6f24796c5bf75c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f3956c8ef694afeaac299674dfb3983"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import numpy as np\n\n\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n\n    return preds, labels\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    result = {\"bleu\": result[\"score\"]}\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T10:52:12.787004Z","iopub.execute_input":"2024-12-05T10:52:12.787555Z","iopub.status.idle":"2024-12-05T10:52:12.794696Z","shell.execute_reply.started":"2024-12-05T10:52:12.787526Z","shell.execute_reply":"2024-12-05T10:52:12.793710Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"!pip install -U transformers --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T10:56:55.333654Z","iopub.execute_input":"2024-12-05T10:56:55.334049Z","iopub.status.idle":"2024-12-05T10:57:03.922877Z","shell.execute_reply.started":"2024-12-05T10:56:55.334021Z","shell.execute_reply":"2024-12-05T10:57:03.921814Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T10:57:50.388479Z","iopub.execute_input":"2024-12-05T10:57:50.389490Z","iopub.status.idle":"2024-12-05T10:57:50.779886Z","shell.execute_reply.started":"2024-12-05T10:57:50.389439Z","shell.execute_reply":"2024-12-05T10:57:50.779108Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"hf_tuto\",\n    eval_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=10,\n    predict_with_generate=True,\n    fp16=True, #change to bf16=True for XPU\n    push_to_hub=True,\n)\n\ntraining_args.average_tokens_across_devices = False\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_ds[\"train\"],\n    eval_dataset=tokenized_ds[\"validation\"],\n    tokenizer=tokenizer, #change to processing_class = tokenizer if higher version of transformers\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T11:00:17.757455Z","iopub.execute_input":"2024-12-05T11:00:17.757828Z","iopub.status.idle":"2024-12-05T11:02:06.088066Z","shell.execute_reply.started":"2024-12-05T11:00:17.757796Z","shell.execute_reply":"2024-12-05T11:02:06.086611Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2036904598.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='292' max='2910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 292/2910 01:45 < 15:52, 2.75 it/s, Epoch 1/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  # 2. reshape scores as [batch_size*vocab_size, # generation steps] with # generation steps being\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 27\u001b[0m\n\u001b[1;32m     15\u001b[0m training_args\u001b[38;5;241m.\u001b[39maverage_tokens_across_devices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     18\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     19\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 27\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2114\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2112\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   2113\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 2114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2115\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2119\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2120\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2121\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2573\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2572\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2573\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[1;32m   2577\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3004\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   3002\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 3004\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   3007\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_checkpoint(model, trial, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2958\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   2957\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 2958\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2959\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2961\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer_seq2seq.py:195\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs \u001b[38;5;241m=\u001b[39m gen_kwargs\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3975\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3972\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3974\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3975\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3985\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3986\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:4169\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4166\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   4168\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 4169\u001b[0m losses, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4170\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4171\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   4172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4173\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer_seq2seq.py:331\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys, **gen_kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m summon_full_params_context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    325\u001b[0m     FullyShardedDataParallel\u001b[38;5;241m.\u001b[39msummon_full_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, FullyShardedDataParallel)\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext()\n\u001b[1;32m    328\u001b[0m )\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m summon_full_params_context:\n\u001b[0;32m--> 331\u001b[0m     generated_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# Temporary hack to ensure the generation config is not initialized for each iteration of the evaluation loop\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;66;03m# TODO: remove this hack when the legacy code that initializes generation_config from a model config is\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# removed in https://github.com/huggingface/transformers/blob/98d88b23f54e5a23e741833f1e973fdf600cc2c5/src/transformers/generation/utils.py#L1183\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39m_from_model_config:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2048\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:3001\u001b[0m, in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2991\u001b[0m     next_model_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(\n\u001b[1;32m   2992\u001b[0m         top_k_ids[:, selected_idx]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs\n\u001b[1;32m   2993\u001b[0m     )\n\u001b[1;32m   2995\u001b[0m     selected_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\n\u001b[1;32m   2996\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnext_model_input,\n\u001b[1;32m   2997\u001b[0m         return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2998\u001b[0m         output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   2999\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   3000\u001b[0m     )\n\u001b[0;32m-> 3001\u001b[0m     next_past_key_values \u001b[38;5;241m=\u001b[39m selected_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3003\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3004\u001b[0m     _, next_past_key_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_past_from_model_output(outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:346\u001b[0m, in \u001b[0;36mprepare_inputs_for_generation\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGenerationMixin\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    A class containing all functions for auto-regressive text generation, to be used as a mixin in [`PreTrainedModel`].\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m    The class exposes [`~generation.GenerationMixin.generate`], which can be used for:\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m        - *greedy decoding* if `num_beams=1` and `do_sample=False`\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m        - *contrastive search* if `penalty_alpha>0` and `top_k>1`\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m        - *multinomial sampling* if `num_beams=1` and `do_sample=True`\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m        - *beam-search decoding* if `num_beams>1` and `do_sample=False`\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m        - *beam-search multinomial sampling* if `num_beams>1` and `do_sample=True`\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m        - *diverse beam-search decoding* if `num_beams>1` and `num_beam_groups>1`\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03m        - *constrained beam-search decoding* if `constraints!=None` or `force_words_ids!=None`\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m        - *assisted decoding* if `assistant_model` or `prompt_lookup_num_tokens` is passed to `.generate()`\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m    To learn more about decoding strategies refer to the [text generation strategies guide](../generation_strategies).\u001b[39;00m\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_inputs_for_generation\u001b[39m(\n\u001b[1;32m    349\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m         input_ids: torch\u001b[38;5;241m.\u001b[39mLongTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    356\u001b[0m     ):\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m        Prepare the model inputs for generation. In includes operations like computing the 4D attention mask or\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m        slicing inputs given the existing cache.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m        requirements for e.g. `past_key_values`). This function should work as is for most LLMs.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n","\u001b[0;31mNotImplementedError\u001b[0m: A model class needs to define a `prepare_inputs_for_generation` method in order to use `.generate()`."],"ename":"NotImplementedError","evalue":"A model class needs to define a `prepare_inputs_for_generation` method in order to use `.generate()`.","output_type":"error"}],"execution_count":19},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import pipeline\n\ntext = tokenized\ntranslator = pipeline(\"translation_xx_to_yy\", model=\"username/hf_tuto\")\ntranslator(text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# NLLB tuto","metadata":{}},{"cell_type":"code","source":"!pip install datasets evaluate transformers==4.33.1 accelerate peft==0.13 bitsandbytes --quiet\n!pip install sacrebleu --quiet\n!pip install huggingface_hub --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T17:30:54.331618Z","iopub.execute_input":"2024-12-10T17:30:54.332356Z","iopub.status.idle":"2024-12-10T17:31:32.848987Z","shell.execute_reply.started":"2024-12-10T17:30:54.332323Z","shell.execute_reply":"2024-12-10T17:31:32.847996Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T17:31:32.850825Z","iopub.execute_input":"2024-12-10T17:31:32.851100Z","iopub.status.idle":"2024-12-10T17:31:34.274499Z","shell.execute_reply.started":"2024-12-10T17:31:32.851075Z","shell.execute_reply":"2024-12-10T17:31:34.273380Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from datasets import ClassLabel\nfrom datasets import Dataset, DatasetDict\nimport pandas as pd\nimport re\n\ndef retrieve_dataset(split:[\"train\", \"val\", \"test\"] = \"train\", dest_lang:[\"py\", \"cpp\", \"both\"] = \"cpp\") -> Dataset:\n    \"\"\"\n    Retrieves a dataset of dictionaries with the codification:\n        {\"id\": id, \n        \"translation\":\n            {\"py\":pycode, \n            \"cpp\":cppcode}}\n    According to the split selected\n    \"\"\"\n\n    #Load the files\n    with open(f\"/kaggle/input/snippets/C++-Python/{split}-C++-map.jsonl\", \"r\") as f: cppids = f.read()\n    with open(f\"/kaggle/input/snippets/C++-Python/{split}-Python-map.jsonl\", \"r\") as f: pyids = f.read()\n    with open(f\"/kaggle/input/snippets/C++-Python/{split}-C++-Python-tok.cpp\", \"r\") as f: cppcode = f.read()\n    with open(f\"/kaggle/input/snippets/C++-Python/{split}-C++-Python-tok.py\", \"r\") as f: pycode = f.read()\n\n    #Divide the text\n    pyids = pyids.replace(\"Python\", \"py\"); pyids = re.findall(r\"(\\d+)-(py)-(\\d+)\", pyids)\n    cppids = cppids.replace(\"C++\", \"cpp\"); cppids = re.findall(r\"(\\d+)-(cpp)-(\\d+)\", cppids)\n    pycode = pycode.split(\"\\n\")[:-1]\n    cppcode = cppcode.split(\"\\n\")[:-1]\n\n    assert len(pycode) == len(pyids) and len(cppcode) == len(cppids) #Ids and lines of code are of equal length\n\n    ids = []\n    for i, lang, j in pyids:\n        if i not in ids:\n            ids.append(i)\n    \n    assert all(i in ids for i, lang, j in cppids) #Same ids for cpp and py\n\n    #Create list of dicts with the desired codification\n    idpy, idcpp = 0, 0\n    dataset = []\n    \n    for i in ids:\n        dic = {\"source_text\": \"\", \"dest_text\": \"\", \"dest_lang\": \"\"}\n        pytrans, cpptrans = pycode[idpy], cppcode[idcpp]\n        idpy += 1; idcpp += 1\n        while idpy < len(pyids) and i in pyids[idpy]:\n            pytrans += \"\\n\" + pycode[idpy]\n            idpy += 1\n        while idcpp < len(cppids) and i in cppids[idcpp]:\n            cpptrans += \"\\n\" + cppcode[idcpp]\n            idcpp += 1\n\n        if dest_lang == \"cpp\" or dest_lang == \"both\":\n            dic[\"source_text\"]= pytrans\n            dic[\"dest_text\"] = cpptrans\n            dic[\"dest_lang\"] = \"cpp\"\n            dataset.append(dic)\n        if dest_lang == \"both\":\n            dic = {\"source_text\": \"\", \"dest_text\": \"\", \"dest_lang\": \"\"}\n        if dest_lang == \"py\" or dest_lang == \"both\":\n            dic[\"source_text\"]= cpptrans\n            dic[\"dest_text\"] = pytrans\n            dic[\"dest_lang\"] = \"py\"\n            dataset.append(dic)\n\n\n    #Create the final dataset\n    split_ds = Dataset.from_pandas(pd.DataFrame(data=dataset))\n    return split_ds\n\n\ndef retrieve_all(dest_lang:[\"py\", \"cpp\", \"both\"] = \"cpp\") -> DatasetDict:\n    \"\"\"\n    Retrieves a DatasetDict of Datasets cointaining the data of each split\n    \"\"\"\n    \n    train_ds = retrieve_dataset(dest_lang = dest_lang)\n    val_ds = retrieve_dataset(\"val\", dest_lang = dest_lang)\n    test_ds = retrieve_dataset(\"test\", dest_lang = dest_lang)\n    ds = DatasetDict({\"train\": train_ds, \"validation\": val_ds, \"test\": test_ds})\n    return ds.class_encode_column(\"dest_lang\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T17:31:34.275921Z","iopub.execute_input":"2024-12-10T17:31:34.276174Z","iopub.status.idle":"2024-12-10T17:31:35.375239Z","shell.execute_reply.started":"2024-12-10T17:31:34.276150Z","shell.execute_reply":"2024-12-10T17:31:35.374616Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"max_tok_length = 128\nlang = \"cpp\"\nraw_datasets = retrieve_all(dest_lang = lang)\n\nfrom transformers import AutoTokenizer\n\ncheckpoint = \"facebook/nllb-200-distilled-600M\"\n# from flores200_codes import flores_codes\nsrc_code = \"eng_Latn\"\ntgt_code = \"eng_Latn\"\ntokenizer = AutoTokenizer.from_pretrained(\n    checkpoint, \n    padding=True, \n    pad_to_multiple_of=8, \n    src_lang=src_code, \n    tgt_lang=tgt_code, \n    truncation=True, \n    max_length=max_tok_length,\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T17:31:35.377509Z","iopub.execute_input":"2024-12-10T17:31:35.378225Z","iopub.status.idle":"2024-12-10T17:31:55.172430Z","shell.execute_reply.started":"2024-12-10T17:31:35.378186Z","shell.execute_reply":"2024-12-10T17:31:55.171755Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Casting to class labels:   0%|          | 0/9308 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fc88b4b3bfb4acd9b599bf8227b9245"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting to class labels:   0%|          | 0/477 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cbcc24cf3a2453682d8180541e49885"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting to class labels:   0%|          | 0/890 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eacdc00aba2a4361bddd92cf00a4bb38"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ebddcacbd664f20bf69bce0e76a3005"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9438e3d32ac844ea9db9c5d60faa4b62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbff5ed705984092a255af6f0aa75a0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2b02fa47941434ca435035f32e301a8"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def preprocess_function(sample):\n    model_inputs = tokenizer(\n        sample[\"source_text\"], \n        text_target = sample[\"dest_text\"],\n        )\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T17:31:55.173428Z","iopub.execute_input":"2024-12-10T17:31:55.173857Z","iopub.status.idle":"2024-12-10T17:31:55.178064Z","shell.execute_reply.started":"2024-12-10T17:31:55.173828Z","shell.execute_reply":"2024-12-10T17:31:55.177261Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)\ntokenized_datasets = tokenized_datasets.filter(lambda x: len(x[\"input_ids\"]) <= max_tok_length and len(x[\"labels\"]) <= max_tok_length , desc=f\"Discarding source and target sentences with more than {max_tok_length} tokens\")\ndic = []\nfor sample in tokenized_datasets['train']:\n    sample_length = len(sample['input_ids'])\n    dic.append(sample_length)\n\nimport pandas as pd\ndf = pd.DataFrame({\"length\":dic})\ndf.hist(bins = 100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T17:31:55.179208Z","iopub.execute_input":"2024-12-10T17:31:55.179549Z","iopub.status.idle":"2024-12-10T17:32:05.590484Z","shell.execute_reply.started":"2024-12-10T17:31:55.179512Z","shell.execute_reply":"2024-12-10T17:32:05.589734Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9308 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49dcae90e9254c5f8afd48850a75dc24"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 1024). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/477 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3197d8654e742548e4d27c72765b563"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/890 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da867e1451b84a88aa1f91e7badcb9aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Discarding source and target sentences with more than 128 tokens:   0%|          | 0/9308 [00:00<?, ? examples…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"731782fb91634cd18347d3b3b658c4df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Discarding source and target sentences with more than 128 tokens:   0%|          | 0/477 [00:00<?, ? examples/…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec11a475ef134afebdcf16163f2395bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Discarding source and target sentences with more than 128 tokens:   0%|          | 0/890 [00:00<?, ? examples/…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5777217d9fb3408ba5f2a249f4b9c8c1"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"array([[<Axes: title={'center': 'length'}>]], dtype=object)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import torch\nfrom transformers import BitsAndBytesConfig\n\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=torch.bfloat16,\n)\n\n\nfrom transformers import AutoModelForSeq2SeqLM\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\n    checkpoint,\n    quantization_config=quantization_config\n    )\n\nfrom peft import prepare_model_for_kbit_training\n\nmodel = prepare_model_for_kbit_training(model, use_gradient_checkpointing=False, gradient_checkpointing_kwargs={'use_reentrant':False})\n\nfrom peft import LoraConfig, get_peft_model\n\nconfig = LoraConfig(\n    task_type=\"SEQ_2_SEQ_LM\",\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n)\n\nlora_model = get_peft_model(model, config)\nlora_model.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T17:32:05.591445Z","iopub.execute_input":"2024-12-10T17:32:05.591711Z","iopub.status.idle":"2024-12-10T17:32:39.968714Z","shell.execute_reply.started":"2024-12-10T17:32:05.591685Z","shell.execute_reply":"2024-12-10T17:32:39.967850Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00aab4b79c4847ceb3e13b90f1962013"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87e8cde05bfb42d788884e593e4d0755"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:488: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return torch.load(checkpoint_file, map_location=map_location)\n/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:488: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return torch.load(checkpoint_file, map_location=map_location)\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0f89e2a4a5143088e9a1f7c9ce97fe2"}},"metadata":{}},{"name":"stdout","text":"trainable params: 2,359,296 || all params: 1,142,142,976 || trainable%: 0.2066\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer=tokenizer, \n    model=lora_model, \n    pad_to_multiple_of=8\n    )\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T17:32:39.970073Z","iopub.execute_input":"2024-12-10T17:32:39.970984Z","iopub.status.idle":"2024-12-10T17:32:40.450150Z","shell.execute_reply.started":"2024-12-10T17:32:39.970941Z","shell.execute_reply":"2024-12-10T17:32:40.449435Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"!pip install unbabel-comet --quiet\nfrom evaluate import load\n\nmetric = load(\"sacrebleu\")\ncomet = load(\"comet\")\n\nimport numpy as np\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n\n    return preds, labels\n\ndef compute_metrics(eval_preds, source_text = None):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    # Replace negative ids in the labels as we can't decode them.\n    #labels = np.where(labels < 0, labels, tokenizer.pad_token_id)\n    for i in range(len(labels)):\n        labels[i] = [tokenizer.pad_token_id if j<0 else j for j in labels[i]]\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Some simple post-processing\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    result = {\"bleu\": result[\"score\"]}\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    #va a dar error la siguiente línea, no worries\n    if source_text is not None:\n        resultcomet = comet.compute(sources = source_text, predictions=decoded_preds, references=decoded_labels)\n        result[\"comet\"] = resultcomet[\"mean_score\"]\n        result[\"comet_all\"] = resultcomet[\"scores\"]\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T17:32:40.451186Z","iopub.execute_input":"2024-12-10T17:32:40.451773Z","iopub.status.idle":"2024-12-10T17:33:29.439057Z","shell.execute_reply.started":"2024-12-10T17:32:40.451744Z","shell.execute_reply":"2024-12-10T17:33:29.438078Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.5 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 4.25.5 which is incompatible.\ngoogle-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.5 which is incompatible.\ngoogle-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 4.25.5 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.5 which is incompatible.\nkfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.5 which is incompatible.\ntensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.5 which is incompatible.\ntensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec0e8e3afae943a19c6450940cfed6d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.97k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cc274fbfebf401197b46bab48359860"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45b3ef14252a44e1b0bc52581677b8da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"hparams.yaml:   0%|          | 0.00/567 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23ce644e7a6045d488507fc54760c957"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fd4fe206cc043debc087f615767d484"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/3.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7c2779803204ca881430f7c33b6c7e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"LICENSE:   0%|          | 0.00/9.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dacbdbc2ea94f2c86b6e51c73463478"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.ckpt:   0%|          | 0.00/2.32G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e72c86eefd7047f1abc51b3b78eb5772"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd9e5450406540fd9fa963b24f21b13d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62312337e78d46bfa37ebad9b48f1d35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a64589f1808c44a981ab3b05b240ff1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e370c048754a4a3d9df1dce0ee1e4297"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\nbatch_size = 8\nmodel_name = checkpoint.split(\"/\")[-1]\nargs = Seq2SeqTrainingArguments(\n    f\"{model_name}-finetuned-py2cpp\",\n    evaluation_strategy = \"epoch\",\n    learning_rate=1e-4,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    save_total_limit=2,\n    num_train_epochs=10,\n    predict_with_generate=True,\n    push_to_hub=True,\n)\n\nfrom transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    lora_model,\n    args,\n    train_dataset=tokenized_datasets['train'],\n    eval_dataset=tokenized_datasets['validation'],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\ntrainer.train()\ntrainer.push_to_hub(commit_message=\"Training complete\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T17:33:29.441346Z","iopub.execute_input":"2024-12-10T17:33:29.441946Z","iopub.status.idle":"2024-12-10T18:05:42.404619Z","shell.execute_reply.started":"2024-12-10T17:33:29.441916Z","shell.execute_reply":"2024-12-10T18:05:42.403954Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:457: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113684699999895, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de0414551273417e99581b2064ec5a2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241210_173336-zrm77xaa</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/hyperloopupv/huggingface/runs/zrm77xaa' target=\"_blank\">silver-water-34</a></strong> to <a href='https://wandb.ai/hyperloopupv/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/hyperloopupv/huggingface' target=\"_blank\">https://wandb.ai/hyperloopupv/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/hyperloopupv/huggingface/runs/zrm77xaa' target=\"_blank\">https://wandb.ai/hyperloopupv/huggingface/runs/zrm77xaa</a>"},"metadata":{}},{"name":"stderr","text":"You're using a NllbTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='670' max='670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [670/670 31:56, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>2.689641</td>\n      <td>29.038900</td>\n      <td>96.545500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.653386</td>\n      <td>30.469300</td>\n      <td>96.672700</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.204596</td>\n      <td>55.046700</td>\n      <td>76.745500</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>1.004844</td>\n      <td>59.551900</td>\n      <td>76.909100</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.917562</td>\n      <td>64.222900</td>\n      <td>75.545500</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>0.860987</td>\n      <td>65.831100</td>\n      <td>73.690900</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>0.816032</td>\n      <td>65.577100</td>\n      <td>76.472700</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.573100</td>\n      <td>0.796779</td>\n      <td>67.955800</td>\n      <td>74.763600</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.573100</td>\n      <td>0.779411</td>\n      <td>67.599400</td>\n      <td>75.800000</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.573100</td>\n      <td>0.773791</td>\n      <td>67.464700</td>\n      <td>75.945500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_model.bin:   0%|          | 0.00/9.49M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6349429f1104806b0e15e14f975e2e7"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/hugo-albert/nllb-200-distilled-600M-finetuned-py2cpp/commit/e58016297e84e84747c40b19358c973fd1308112', commit_message='Training complete', commit_description='', oid='e58016297e84e84747c40b19358c973fd1308112', pr_url=None, repo_url=RepoUrl('https://huggingface.co/hugo-albert/nllb-200-distilled-600M-finetuned-py2cpp', endpoint='https://huggingface.co', repo_type='model', repo_id='hugo-albert/nllb-200-distilled-600M-finetuned-py2cpp'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from transformers import GenerationConfig\n\ngeneration_config = GenerationConfig.from_pretrained(\n    checkpoint,\n)\n\nprint(generation_config)\n\ntest_batch_size = 32\nbatch_tokenized_test = tokenized_datasets['test'].batch(test_batch_size)\n\nnumber_of_batches = len(batch_tokenized_test[\"source_text\"])\noutput_sequences = []\nfor i in range(number_of_batches):\n    inputs = tokenizer(batch_tokenized_test[\"source_text\"][i], max_length=max_tok_length, truncation=True, return_tensors=\"pt\", padding=True)\n    output_batch = lora_model.generate(generation_config=generation_config, input_ids=inputs[\"input_ids\"].cuda(), attention_mask=inputs[\"attention_mask\"].cuda(), forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_code), max_length = max_tok_length, num_beams=1, do_sample=False,)\n    output_sequences.extend(output_batch.cpu())\n\nresult = compute_metrics((output_sequences,tokenized_datasets['test'][\"labels\"]))\nprint(f'BLEU score: {result[\"bleu\"]}')\n#print(f'COMET score: {result[\"comet\"]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T18:05:42.405507Z","iopub.execute_input":"2024-12-10T18:05:42.405771Z","iopub.status.idle":"2024-12-10T18:06:09.354071Z","shell.execute_reply.started":"2024-12-10T18:05:42.405746Z","shell.execute_reply":"2024-12-10T18:06:09.353183Z"}},"outputs":[{"name":"stdout","text":"GenerationConfig {\n  \"_from_model_config\": true,\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"eos_token_id\": 2,\n  \"max_length\": 200,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.33.1\"\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batching examples:   0%|          | 0/129 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8578949608874ec989a078a2ead04e81"}},"metadata":{}},{"name":"stdout","text":"BLEU score: 68.4979\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import re\n\ndef compute_metrics2(sample, output_sequences):\n    inputs = [f\"{s}\"  for s in sample[\"source_text\"]]\n    preds = tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n    #print(inputs)\n    #print(preds)\n    for i, (input,pred) in enumerate(zip(inputs,preds)):\n      pred = re.search(r'^.*\\n',pred.removeprefix(input).lstrip())\n      if pred is not None:\n        preds[i] = pred.group()[:-1]\n      else:\n        preds[i] = \"\"\n    #print(sample[\"source_text\"])\n    #print(sample[\"dest_text\"])\n    #print(preds)\n    resultcomet = comet.compute(sources = sample[\"source_text\"], predictions=preds, references=sample[\"dest_text\"])\n    resultbleu = metric.compute(predictions=preds, references=sample[\"dest_text\"])\n    result = {\"bleu\": resultbleu[\"score\"], \"comet\": resultcomet[\"mean_score\"], \"comet_all\": resultcomet[\"scores\"]}\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T18:06:09.355128Z","iopub.execute_input":"2024-12-10T18:06:09.355385Z","iopub.status.idle":"2024-12-10T18:06:09.362405Z","shell.execute_reply.started":"2024-12-10T18:06:09.355359Z","shell.execute_reply":"2024-12-10T18:06:09.361544Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"result = compute_metrics2(tokenized_datasets['test'],output_sequences)\nprint(f'COMET score: {result[\"comet\"]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T18:06:09.363566Z","iopub.execute_input":"2024-12-10T18:06:09.364196Z","iopub.status.idle":"2024-12-10T18:06:19.962525Z","shell.execute_reply.started":"2024-12-10T18:06:09.364157Z","shell.execute_reply":"2024-12-10T18:06:19.961671Z"}},"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"COMET score: 0.25355507907017255\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def check_translation(i):\n    print(f\"COMET of snippet {i}:\", result[\"comet_all\"][i])\n    print(\"REAL: \\n\", tokenized_datasets['test'][\"dest_text\"][i].replace(\"NEW_LINE\", \"\\n\"))\n    print(\"PRED: \\n\", tokenizer.batch_decode(output_sequences, skip_special_tokens=True)[i].replace(\"NEW_LINE\", \"\\n\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T18:06:19.963684Z","iopub.execute_input":"2024-12-10T18:06:19.963966Z","iopub.status.idle":"2024-12-10T18:06:19.969429Z","shell.execute_reply.started":"2024-12-10T18:06:19.963937Z","shell.execute_reply":"2024-12-10T18:06:19.968563Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"for i in range(len(result[\"comet_all\"])):\n    if result[\"comet_all\"][i] > 0.3:\n        check_translation(i)\n        break\n\nprint(\"===================\")\nfor i in range(len(result[\"comet_all\"])):\n    if result[\"comet_all\"][i] < 0.3:\n        check_translation(i)\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T18:06:19.970565Z","iopub.execute_input":"2024-12-10T18:06:19.970920Z","iopub.status.idle":"2024-12-10T18:06:20.001584Z","shell.execute_reply.started":"2024-12-10T18:06:19.970882Z","shell.execute_reply":"2024-12-10T18:06:20.000785Z"}},"outputs":[{"name":"stdout","text":"COMET of snippet 27: 0.30128785967826843\nREAL: \n int area_fun ( int side ) { int area = side * side ; return area ; }\nint main ( ) { int side = 4 ; int area = area_fun ( side ) ; cout << area ; return 0 ; }\nPRED: \n int area_fun ( side ) { int area = side * side ; return area ; } int side = 4 ; int area = area_fun ( side ) ; cout << area << endl ; return 0 ; }\n===================\nCOMET of snippet 0: 0.25471988320350647\nREAL: \n void checkSolution ( int a , int b , int c ) { if ( a == c ) cout << \" Yes \" ; else cout << \" No \" ; }\nint main ( ) { int a = 2 , b = 0 , c = 2 ; checkSolution ( a , b , c ) ; return 0 ; }\nPRED: \n void checkSolution ( int a, int b, int c ) { if ( a == c ) cout << \" Yes \" ; else cout << \" No \" ; } int main ( ) { int a = 2 ; b = 0 ; c = 2 ; checkSolution ( a, b, c ) ; return 0 ; }\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(result[\"comet_all\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T18:07:42.133501Z","iopub.execute_input":"2024-12-10T18:07:42.133866Z","iopub.status.idle":"2024-12-10T18:07:42.359986Z","shell.execute_reply.started":"2024-12-10T18:07:42.133835Z","shell.execute_reply":"2024-12-10T18:07:42.359166Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(array([ 7., 13., 23., 12., 25., 15., 16.,  8.,  6.,  4.]),\n array([0.21564448, 0.22420882, 0.23277315, 0.24133749, 0.24990183,\n        0.25846617, 0.26703051, 0.27559485, 0.28415918, 0.29272352,\n        0.30128786]),\n <BarContainer object of 10 artists>)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":16}]}