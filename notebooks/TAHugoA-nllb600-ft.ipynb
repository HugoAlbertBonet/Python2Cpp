{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLLB tuto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T17:30:54.332356Z",
     "iopub.status.busy": "2024-12-10T17:30:54.331618Z",
     "iopub.status.idle": "2024-12-10T17:31:32.848987Z",
     "shell.execute_reply": "2024-12-10T17:31:32.847996Z",
     "shell.execute_reply.started": "2024-12-10T17:30:54.332323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install datasets evaluate transformers==4.33.1 accelerate peft==0.13 bitsandbytes --quiet\n",
    "!pip install sacrebleu --quiet\n",
    "!pip install huggingface_hub --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T17:31:32.851100Z",
     "iopub.status.busy": "2024-12-10T17:31:32.850825Z",
     "iopub.status.idle": "2024-12-10T17:31:34.274499Z",
     "shell.execute_reply": "2024-12-10T17:31:34.273380Z",
     "shell.execute_reply.started": "2024-12-10T17:31:32.851075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T17:31:34.276174Z",
     "iopub.status.busy": "2024-12-10T17:31:34.275921Z",
     "iopub.status.idle": "2024-12-10T17:31:35.375239Z",
     "shell.execute_reply": "2024-12-10T17:31:35.374616Z",
     "shell.execute_reply.started": "2024-12-10T17:31:34.276150Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import ClassLabel\n",
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def retrieve_dataset(split:[\"train\", \"val\", \"test\"] = \"train\", dest_lang:[\"py\", \"cpp\", \"both\"] = \"cpp\") -> Dataset:\n",
    "    \"\"\"\n",
    "    Retrieves a dataset of dictionaries with the codification:\n",
    "        {\"id\": id, \n",
    "        \"translation\":\n",
    "            {\"py\":pycode, \n",
    "            \"cpp\":cppcode}}\n",
    "    According to the split selected\n",
    "    \"\"\"\n",
    "\n",
    "    #Load the files\n",
    "    with open(f\"/kaggle/input/snippets/C++-Python/{split}-C++-map.jsonl\", \"r\") as f: cppids = f.read()\n",
    "    with open(f\"/kaggle/input/snippets/C++-Python/{split}-Python-map.jsonl\", \"r\") as f: pyids = f.read()\n",
    "    with open(f\"/kaggle/input/snippets/C++-Python/{split}-C++-Python-tok.cpp\", \"r\") as f: cppcode = f.read()\n",
    "    with open(f\"/kaggle/input/snippets/C++-Python/{split}-C++-Python-tok.py\", \"r\") as f: pycode = f.read()\n",
    "\n",
    "    #Divide the text\n",
    "    pyids = pyids.replace(\"Python\", \"py\"); pyids = re.findall(r\"(\\d+)-(py)-(\\d+)\", pyids)\n",
    "    cppids = cppids.replace(\"C++\", \"cpp\"); cppids = re.findall(r\"(\\d+)-(cpp)-(\\d+)\", cppids)\n",
    "    pycode = pycode.split(\"\\n\")[:-1]\n",
    "    cppcode = cppcode.split(\"\\n\")[:-1]\n",
    "\n",
    "    assert len(pycode) == len(pyids) and len(cppcode) == len(cppids) #Ids and lines of code are of equal length\n",
    "\n",
    "    ids = []\n",
    "    for i, lang, j in pyids:\n",
    "        if i not in ids:\n",
    "            ids.append(i)\n",
    "    \n",
    "    assert all(i in ids for i, lang, j in cppids) #Same ids for cpp and py\n",
    "\n",
    "    #Create list of dicts with the desired codification\n",
    "    idpy, idcpp = 0, 0\n",
    "    dataset = []\n",
    "    \n",
    "    for i in ids:\n",
    "        dic = {\"source_text\": \"\", \"dest_text\": \"\", \"dest_lang\": \"\"}\n",
    "        pytrans, cpptrans = pycode[idpy], cppcode[idcpp]\n",
    "        idpy += 1; idcpp += 1\n",
    "        while idpy < len(pyids) and i in pyids[idpy]:\n",
    "            pytrans += \"\\n\" + pycode[idpy]\n",
    "            idpy += 1\n",
    "        while idcpp < len(cppids) and i in cppids[idcpp]:\n",
    "            cpptrans += \"\\n\" + cppcode[idcpp]\n",
    "            idcpp += 1\n",
    "\n",
    "        if dest_lang == \"cpp\" or dest_lang == \"both\":\n",
    "            dic[\"source_text\"]= pytrans\n",
    "            dic[\"dest_text\"] = cpptrans\n",
    "            dic[\"dest_lang\"] = \"cpp\"\n",
    "            dataset.append(dic)\n",
    "        if dest_lang == \"both\":\n",
    "            dic = {\"source_text\": \"\", \"dest_text\": \"\", \"dest_lang\": \"\"}\n",
    "        if dest_lang == \"py\" or dest_lang == \"both\":\n",
    "            dic[\"source_text\"]= cpptrans\n",
    "            dic[\"dest_text\"] = pytrans\n",
    "            dic[\"dest_lang\"] = \"py\"\n",
    "            dataset.append(dic)\n",
    "\n",
    "\n",
    "    #Create the final dataset\n",
    "    split_ds = Dataset.from_pandas(pd.DataFrame(data=dataset))\n",
    "    return split_ds\n",
    "\n",
    "\n",
    "def retrieve_all(dest_lang:[\"py\", \"cpp\", \"both\"] = \"cpp\") -> DatasetDict:\n",
    "    \"\"\"\n",
    "    Retrieves a DatasetDict of Datasets cointaining the data of each split\n",
    "    \"\"\"\n",
    "    \n",
    "    train_ds = retrieve_dataset(dest_lang = dest_lang)\n",
    "    val_ds = retrieve_dataset(\"val\", dest_lang = dest_lang)\n",
    "    test_ds = retrieve_dataset(\"test\", dest_lang = dest_lang)\n",
    "    ds = DatasetDict({\"train\": train_ds, \"validation\": val_ds, \"test\": test_ds})\n",
    "    return ds.class_encode_column(\"dest_lang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T17:31:35.378225Z",
     "iopub.status.busy": "2024-12-10T17:31:35.377509Z",
     "iopub.status.idle": "2024-12-10T17:31:55.172430Z",
     "shell.execute_reply": "2024-12-10T17:31:55.171755Z",
     "shell.execute_reply.started": "2024-12-10T17:31:35.378186Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc88b4b3bfb4acd9b599bf8227b9245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/9308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbcc24cf3a2453682d8180541e49885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/477 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eacdc00aba2a4361bddd92cf00a4bb38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/890 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ebddcacbd664f20bf69bce0e76a3005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9438e3d32ac844ea9db9c5d60faa4b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbff5ed705984092a255af6f0aa75a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b02fa47941434ca435035f32e301a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_tok_length = 128\n",
    "lang = \"cpp\"\n",
    "raw_datasets = retrieve_all(dest_lang = lang)\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"facebook/nllb-200-distilled-600M\"\n",
    "# from flores200_codes import flores_codes\n",
    "src_code = \"eng_Latn\"\n",
    "tgt_code = \"eng_Latn\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    checkpoint, \n",
    "    padding=True, \n",
    "    pad_to_multiple_of=8, \n",
    "    src_lang=src_code, \n",
    "    tgt_lang=tgt_code, \n",
    "    truncation=True, \n",
    "    max_length=max_tok_length,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T17:31:55.173857Z",
     "iopub.status.busy": "2024-12-10T17:31:55.173428Z",
     "iopub.status.idle": "2024-12-10T17:31:55.178064Z",
     "shell.execute_reply": "2024-12-10T17:31:55.177261Z",
     "shell.execute_reply.started": "2024-12-10T17:31:55.173828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_function(sample):\n",
    "    model_inputs = tokenizer(\n",
    "        sample[\"source_text\"], \n",
    "        text_target = sample[\"dest_text\"],\n",
    "        )\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T17:31:55.179549Z",
     "iopub.status.busy": "2024-12-10T17:31:55.179208Z",
     "iopub.status.idle": "2024-12-10T17:32:05.590484Z",
     "shell.execute_reply": "2024-12-10T17:32:05.589734Z",
     "shell.execute_reply.started": "2024-12-10T17:31:55.179512Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49dcae90e9254c5f8afd48850a75dc24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3197d8654e742548e4d27c72765b563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/477 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da867e1451b84a88aa1f91e7badcb9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/890 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731782fb91634cd18347d3b3b658c4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Discarding source and target sentences with more than 128 tokens:   0%|          | 0/9308 [00:00<?, ? examples…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec11a475ef134afebdcf16163f2395bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Discarding source and target sentences with more than 128 tokens:   0%|          | 0/477 [00:00<?, ? examples/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5777217d9fb3408ba5f2a249f4b9c8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Discarding source and target sentences with more than 128 tokens:   0%|          | 0/890 [00:00<?, ? examples/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'length'}>]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.filter(lambda x: len(x[\"input_ids\"]) <= max_tok_length and len(x[\"labels\"]) <= max_tok_length , desc=f\"Discarding source and target sentences with more than {max_tok_length} tokens\")\n",
    "dic = []\n",
    "for sample in tokenized_datasets['train']:\n",
    "    sample_length = len(sample['input_ids'])\n",
    "    dic.append(sample_length)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"length\":dic})\n",
    "df.hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T17:32:05.591711Z",
     "iopub.status.busy": "2024-12-10T17:32:05.591445Z",
     "iopub.status.idle": "2024-12-10T17:32:39.968714Z",
     "shell.execute_reply": "2024-12-10T17:32:39.967850Z",
     "shell.execute_reply.started": "2024-12-10T17:32:05.591685Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00aab4b79c4847ceb3e13b90f1962013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e8cde05bfb42d788884e593e4d0755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:488: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:488: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f89e2a4a5143088e9a1f7c9ce97fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,359,296 || all params: 1,142,142,976 || trainable%: 0.2066\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    checkpoint,\n",
    "    quantization_config=quantization_config\n",
    "    )\n",
    "\n",
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=False, gradient_checkpointing_kwargs={'use_reentrant':False})\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(model, config)\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T17:32:39.970984Z",
     "iopub.status.busy": "2024-12-10T17:32:39.970073Z",
     "iopub.status.idle": "2024-12-10T17:32:40.450150Z",
     "shell.execute_reply": "2024-12-10T17:32:40.449435Z",
     "shell.execute_reply.started": "2024-12-10T17:32:39.970941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer, \n",
    "    model=lora_model, \n",
    "    pad_to_multiple_of=8\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T17:32:40.451773Z",
     "iopub.status.busy": "2024-12-10T17:32:40.451186Z",
     "iopub.status.idle": "2024-12-10T17:33:29.439057Z",
     "shell.execute_reply": "2024-12-10T17:33:29.438078Z",
     "shell.execute_reply.started": "2024-12-10T17:32:40.451744Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n",
      "apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.5 which is incompatible.\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\n",
      "google-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 4.25.5 which is incompatible.\n",
      "google-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.5 which is incompatible.\n",
      "google-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 4.25.5 which is incompatible.\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n",
      "kfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.5 which is incompatible.\n",
      "kfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.5 which is incompatible.\n",
      "tensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.5 which is incompatible.\n",
      "tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0e8e3afae943a19c6450940cfed6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc274fbfebf401197b46bab48359860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.97k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b3ef14252a44e1b0bc52581677b8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ce644e7a6045d488507fc54760c957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hparams.yaml:   0%|          | 0.00/567 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd4fe206cc043debc087f615767d484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c2779803204ca881430f7c33b6c7e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dacbdbc2ea94f2c86b6e51c73463478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE:   0%|          | 0.00/9.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72c86eefd7047f1abc51b3b78eb5772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.ckpt:   0%|          | 0.00/2.32G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9e5450406540fd9fa963b24f21b13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62312337e78d46bfa37ebad9b48f1d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64589f1808c44a981ab3b05b240ff1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e370c048754a4a3d9df1dce0ee1e4297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n"
     ]
    }
   ],
   "source": [
    "!pip install unbabel-comet --quiet\n",
    "from evaluate import load\n",
    "\n",
    "metric = load(\"sacrebleu\")\n",
    "comet = load(\"comet\")\n",
    "\n",
    "import numpy as np\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds, source_text = None):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace negative ids in the labels as we can't decode them.\n",
    "    #labels = np.where(labels < 0, labels, tokenizer.pad_token_id)\n",
    "    for i in range(len(labels)):\n",
    "        labels[i] = [tokenizer.pad_token_id if j<0 else j for j in labels[i]]\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    #va a dar error la siguiente línea, no worries\n",
    "    if source_text is not None:\n",
    "        resultcomet = comet.compute(sources = source_text, predictions=decoded_preds, references=decoded_labels)\n",
    "        result[\"comet\"] = resultcomet[\"mean_score\"]\n",
    "        result[\"comet_all\"] = resultcomet[\"scores\"]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T17:33:29.441946Z",
     "iopub.status.busy": "2024-12-10T17:33:29.441346Z",
     "iopub.status.idle": "2024-12-10T18:05:42.404619Z",
     "shell.execute_reply": "2024-12-10T18:05:42.403954Z",
     "shell.execute_reply.started": "2024-12-10T17:33:29.441916Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:457: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0414551273417e99581b2064ec5a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113684699999895, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241210_173336-zrm77xaa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hyperloopupv/huggingface/runs/zrm77xaa' target=\"_blank\">silver-water-34</a></strong> to <a href='https://wandb.ai/hyperloopupv/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hyperloopupv/huggingface' target=\"_blank\">https://wandb.ai/hyperloopupv/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hyperloopupv/huggingface/runs/zrm77xaa' target=\"_blank\">https://wandb.ai/hyperloopupv/huggingface/runs/zrm77xaa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a NllbTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='670' max='670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [670/670 31:56, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.689641</td>\n",
       "      <td>29.038900</td>\n",
       "      <td>96.545500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.653386</td>\n",
       "      <td>30.469300</td>\n",
       "      <td>96.672700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.204596</td>\n",
       "      <td>55.046700</td>\n",
       "      <td>76.745500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.004844</td>\n",
       "      <td>59.551900</td>\n",
       "      <td>76.909100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.917562</td>\n",
       "      <td>64.222900</td>\n",
       "      <td>75.545500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.860987</td>\n",
       "      <td>65.831100</td>\n",
       "      <td>73.690900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.816032</td>\n",
       "      <td>65.577100</td>\n",
       "      <td>76.472700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.573100</td>\n",
       "      <td>0.796779</td>\n",
       "      <td>67.955800</td>\n",
       "      <td>74.763600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.573100</td>\n",
       "      <td>0.779411</td>\n",
       "      <td>67.599400</td>\n",
       "      <td>75.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.573100</td>\n",
       "      <td>0.773791</td>\n",
       "      <td>67.464700</td>\n",
       "      <td>75.945500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6349429f1104806b0e15e14f975e2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.bin:   0%|          | 0.00/9.49M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/hugo-albert/nllb-200-distilled-600M-finetuned-py2cpp/commit/e58016297e84e84747c40b19358c973fd1308112', commit_message='Training complete', commit_description='', oid='e58016297e84e84747c40b19358c973fd1308112', pr_url=None, repo_url=RepoUrl('https://huggingface.co/hugo-albert/nllb-200-distilled-600M-finetuned-py2cpp', endpoint='https://huggingface.co', repo_type='model', repo_id='hugo-albert/nllb-200-distilled-600M-finetuned-py2cpp'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "batch_size = 8\n",
    "model_name = checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-py2cpp\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=10,\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    lora_model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T18:05:42.405771Z",
     "iopub.status.busy": "2024-12-10T18:05:42.405507Z",
     "iopub.status.idle": "2024-12-10T18:06:09.354071Z",
     "shell.execute_reply": "2024-12-10T18:06:09.353183Z",
     "shell.execute_reply.started": "2024-12-10T18:05:42.405746Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_length\": 200,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8578949608874ec989a078a2ead04e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batching examples:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 68.4979\n"
     ]
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "generation_config = GenerationConfig.from_pretrained(\n",
    "    checkpoint,\n",
    ")\n",
    "\n",
    "print(generation_config)\n",
    "\n",
    "test_batch_size = 32\n",
    "batch_tokenized_test = tokenized_datasets['test'].batch(test_batch_size)\n",
    "\n",
    "number_of_batches = len(batch_tokenized_test[\"source_text\"])\n",
    "output_sequences = []\n",
    "for i in range(number_of_batches):\n",
    "    inputs = tokenizer(batch_tokenized_test[\"source_text\"][i], max_length=max_tok_length, truncation=True, return_tensors=\"pt\", padding=True)\n",
    "    output_batch = lora_model.generate(generation_config=generation_config, input_ids=inputs[\"input_ids\"].cuda(), attention_mask=inputs[\"attention_mask\"].cuda(), forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_code), max_length = max_tok_length, num_beams=1, do_sample=False,)\n",
    "    output_sequences.extend(output_batch.cpu())\n",
    "\n",
    "result = compute_metrics((output_sequences,tokenized_datasets['test'][\"labels\"]))\n",
    "print(f'BLEU score: {result[\"bleu\"]}')\n",
    "#print(f'COMET score: {result[\"comet\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T18:06:09.355385Z",
     "iopub.status.busy": "2024-12-10T18:06:09.355128Z",
     "iopub.status.idle": "2024-12-10T18:06:09.362405Z",
     "shell.execute_reply": "2024-12-10T18:06:09.361544Z",
     "shell.execute_reply.started": "2024-12-10T18:06:09.355359Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def compute_metrics2(sample, output_sequences):\n",
    "    inputs = [f\"{s}\"  for s in sample[\"source_text\"]]\n",
    "    preds = tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n",
    "    #print(inputs)\n",
    "    #print(preds)\n",
    "    for i, (input,pred) in enumerate(zip(inputs,preds)):\n",
    "      pred = re.search(r'^.*\\n',pred.removeprefix(input).lstrip())\n",
    "      if pred is not None:\n",
    "        preds[i] = pred.group()[:-1]\n",
    "      else:\n",
    "        preds[i] = \"\"\n",
    "    #print(sample[\"source_text\"])\n",
    "    #print(sample[\"dest_text\"])\n",
    "    #print(preds)\n",
    "    resultcomet = comet.compute(sources = sample[\"source_text\"], predictions=preds, references=sample[\"dest_text\"])\n",
    "    resultbleu = metric.compute(predictions=preds, references=sample[\"dest_text\"])\n",
    "    result = {\"bleu\": resultbleu[\"score\"], \"comet\": resultcomet[\"mean_score\"], \"comet_all\": resultcomet[\"scores\"]}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T18:06:09.364196Z",
     "iopub.status.busy": "2024-12-10T18:06:09.363566Z",
     "iopub.status.idle": "2024-12-10T18:06:19.962525Z",
     "shell.execute_reply": "2024-12-10T18:06:19.961671Z",
     "shell.execute_reply.started": "2024-12-10T18:06:09.364157Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMET score: 0.25355507907017255\n"
     ]
    }
   ],
   "source": [
    "result = compute_metrics2(tokenized_datasets['test'],output_sequences)\n",
    "print(f'COMET score: {result[\"comet\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T18:06:19.963966Z",
     "iopub.status.busy": "2024-12-10T18:06:19.963684Z",
     "iopub.status.idle": "2024-12-10T18:06:19.969429Z",
     "shell.execute_reply": "2024-12-10T18:06:19.968563Z",
     "shell.execute_reply.started": "2024-12-10T18:06:19.963937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def check_translation(i):\n",
    "    print(f\"COMET of snippet {i}:\", result[\"comet_all\"][i])\n",
    "    print(\"REAL: \\n\", tokenized_datasets['test'][\"dest_text\"][i].replace(\"NEW_LINE\", \"\\n\"))\n",
    "    print(\"PRED: \\n\", tokenizer.batch_decode(output_sequences, skip_special_tokens=True)[i].replace(\"NEW_LINE\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T18:06:19.970920Z",
     "iopub.status.busy": "2024-12-10T18:06:19.970565Z",
     "iopub.status.idle": "2024-12-10T18:06:20.001584Z",
     "shell.execute_reply": "2024-12-10T18:06:20.000785Z",
     "shell.execute_reply.started": "2024-12-10T18:06:19.970882Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMET of snippet 27: 0.30128785967826843\n",
      "REAL: \n",
      " int area_fun ( int side ) { int area = side * side ; return area ; }\n",
      "int main ( ) { int side = 4 ; int area = area_fun ( side ) ; cout << area ; return 0 ; }\n",
      "PRED: \n",
      " int area_fun ( side ) { int area = side * side ; return area ; } int side = 4 ; int area = area_fun ( side ) ; cout << area << endl ; return 0 ; }\n",
      "===================\n",
      "COMET of snippet 0: 0.25471988320350647\n",
      "REAL: \n",
      " void checkSolution ( int a , int b , int c ) { if ( a == c ) cout << \" Yes \" ; else cout << \" No \" ; }\n",
      "int main ( ) { int a = 2 , b = 0 , c = 2 ; checkSolution ( a , b , c ) ; return 0 ; }\n",
      "PRED: \n",
      " void checkSolution ( int a, int b, int c ) { if ( a == c ) cout << \" Yes \" ; else cout << \" No \" ; } int main ( ) { int a = 2 ; b = 0 ; c = 2 ; checkSolution ( a, b, c ) ; return 0 ; }\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(result[\"comet_all\"])):\n",
    "    if result[\"comet_all\"][i] > 0.3:\n",
    "        check_translation(i)\n",
    "        break\n",
    "\n",
    "print(\"===================\")\n",
    "for i in range(len(result[\"comet_all\"])):\n",
    "    if result[\"comet_all\"][i] < 0.3:\n",
    "        check_translation(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T18:07:42.133866Z",
     "iopub.status.busy": "2024-12-10T18:07:42.133501Z",
     "iopub.status.idle": "2024-12-10T18:07:42.359986Z",
     "shell.execute_reply": "2024-12-10T18:07:42.359166Z",
     "shell.execute_reply.started": "2024-12-10T18:07:42.133835Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 7., 13., 23., 12., 25., 15., 16.,  8.,  6.,  4.]),\n",
       " array([0.21564448, 0.22420882, 0.23277315, 0.24133749, 0.24990183,\n",
       "        0.25846617, 0.26703051, 0.27559485, 0.28415918, 0.29272352,\n",
       "        0.30128786]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(result[\"comet_all\"])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6219636,
     "sourceId": 10087360,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6228461,
     "sourceId": 10098879,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
