{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CodeLLaMa-3-8B finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:26:00.582498Z",
     "iopub.status.busy": "2024-12-07T21:26:00.581593Z",
     "iopub.status.idle": "2024-12-07T21:26:45.780620Z",
     "shell.execute_reply": "2024-12-07T21:26:45.779477Z",
     "shell.execute_reply.started": "2024-12-07T21:26:00.582460Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install datasets evaluate transformers==4.33.1 accelerate peft bitsandbytes --quiet\n",
    "!pip install sacrebleu --quiet\n",
    "!pip install huggingface_hub --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:26:45.783501Z",
     "iopub.status.busy": "2024-12-07T21:26:45.783048Z",
     "iopub.status.idle": "2024-12-07T21:26:47.376157Z",
     "shell.execute_reply": "2024-12-07T21:26:47.375522Z",
     "shell.execute_reply.started": "2024-12-07T21:26:45.783443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import ClassLabel\n",
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def retrieve_dataset(split:[\"train\", \"val\", \"test\"] = \"train\", dest_lang:[\"py\", \"cpp\", \"both\"] = \"cpp\") -> Dataset:\n",
    "    \"\"\"\n",
    "    Retrieves a dataset of dictionaries with the codification:\n",
    "        {\"id\": id, \n",
    "        \"translation\":\n",
    "            {\"py\":pycode, \n",
    "            \"cpp\":cppcode}}\n",
    "    According to the split selected\n",
    "    \"\"\"\n",
    "\n",
    "    #Load the files\n",
    "    with open(f\"/kaggle/input/snippets/C++-Python/{split}-C++-map.jsonl\", \"r\") as f: cppids = f.read()\n",
    "    with open(f\"/kaggle/input/snippets/C++-Python/{split}-Python-map.jsonl\", \"r\") as f: pyids = f.read()\n",
    "    with open(f\"/kaggle/input/snippets/C++-Python/{split}-C++-Python-tok.cpp\", \"r\") as f: cppcode = f.read()\n",
    "    with open(f\"/kaggle/input/snippets/C++-Python/{split}-C++-Python-tok.py\", \"r\") as f: pycode = f.read()\n",
    "\n",
    "    #Divide the text\n",
    "    pyids = pyids.replace(\"Python\", \"py\"); pyids = re.findall(r\"(\\d+)-(py)-(\\d+)\", pyids)\n",
    "    cppids = cppids.replace(\"C++\", \"cpp\"); cppids = re.findall(r\"(\\d+)-(cpp)-(\\d+)\", cppids)\n",
    "    pycode = pycode.split(\"\\n\")[:-1]\n",
    "    cppcode = cppcode.split(\"\\n\")[:-1]\n",
    "\n",
    "    assert len(pycode) == len(pyids) and len(cppcode) == len(cppids) #Ids and lines of code are of equal length\n",
    "\n",
    "    ids = []\n",
    "    for i, lang, j in pyids:\n",
    "        if i not in ids:\n",
    "            ids.append(i)\n",
    "    \n",
    "    assert all(i in ids for i, lang, j in cppids) #Same ids for cpp and py\n",
    "\n",
    "    #Create list of dicts with the desired codification\n",
    "    idpy, idcpp = 0, 0\n",
    "    dataset = []\n",
    "    \n",
    "    for i in ids:\n",
    "        dic = {\"source_text\": \"\", \"dest_text\": \"\", \"dest_lang\": \"\"}\n",
    "        pytrans, cpptrans = pycode[idpy], cppcode[idcpp]\n",
    "        idpy += 1; idcpp += 1\n",
    "        while idpy < len(pyids) and i in pyids[idpy]:\n",
    "            pytrans += \"\\n\" + pycode[idpy]\n",
    "            idpy += 1\n",
    "        while idcpp < len(cppids) and i in cppids[idcpp]:\n",
    "            cpptrans += \"\\n\" + cppcode[idcpp]\n",
    "            idcpp += 1\n",
    "\n",
    "        if dest_lang == \"cpp\" or dest_lang == \"both\":\n",
    "            dic[\"source_text\"]= pytrans\n",
    "            dic[\"dest_text\"] = cpptrans\n",
    "            dic[\"dest_lang\"] = \"cpp\"\n",
    "            dataset.append(dic)\n",
    "        if dest_lang == \"both\":\n",
    "            dic = {\"source_text\": \"\", \"dest_text\": \"\", \"dest_lang\": \"\"}\n",
    "        if dest_lang == \"py\" or dest_lang == \"both\":\n",
    "            dic[\"source_text\"]= cpptrans\n",
    "            dic[\"dest_text\"] = pytrans\n",
    "            dic[\"dest_lang\"] = \"py\"\n",
    "            dataset.append(dic)\n",
    "\n",
    "\n",
    "    #Create the final dataset\n",
    "    split_ds = Dataset.from_pandas(pd.DataFrame(data=dataset))\n",
    "    return split_ds\n",
    "\n",
    "\n",
    "def retrieve_all() -> DatasetDict:\n",
    "    \"\"\"\n",
    "    Retrieves a DatasetDict of Datasets cointaining the data of each split\n",
    "    \"\"\"\n",
    "    \n",
    "    train_ds = retrieve_dataset()\n",
    "    val_ds = retrieve_dataset(\"val\")\n",
    "    test_ds = retrieve_dataset(\"test\")\n",
    "    ds = DatasetDict({\"train\": train_ds, \"validation\": val_ds, \"test\": test_ds})\n",
    "    return ds.class_encode_column(\"dest_lang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:26:47.377294Z",
     "iopub.status.busy": "2024-12-07T21:26:47.376976Z",
     "iopub.status.idle": "2024-12-07T21:27:03.876234Z",
     "shell.execute_reply": "2024-12-07T21:27:03.875370Z",
     "shell.execute_reply.started": "2024-12-07T21:26:47.377271Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f2397752234dadbd7b05484402e3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/9308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e159d02c36430c863c17e609e9bbb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/477 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ca90388fe5442996bdd49c7140edbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/890 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = retrieve_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T16:05:16.254577Z",
     "iopub.status.busy": "2024-12-05T16:05:16.254313Z",
     "iopub.status.idle": "2024-12-05T16:05:16.260765Z",
     "shell.execute_reply": "2024-12-05T16:05:16.259923Z",
     "shell.execute_reply.started": "2024-12-05T16:05:16.254551Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_text': Value(dtype='string', id=None),\n",
       " 'dest_text': Value(dtype='string', id=None),\n",
       " 'dest_lang': ClassLabel(names=['cpp'], id=None)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:27:03.878274Z",
     "iopub.status.busy": "2024-12-07T21:27:03.877995Z",
     "iopub.status.idle": "2024-12-07T21:27:05.278657Z",
     "shell.execute_reply": "2024-12-07T21:27:05.277626Z",
     "shell.execute_reply.started": "2024-12-07T21:27:03.878250Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:37:03.772773Z",
     "iopub.status.busy": "2024-12-07T21:37:03.771944Z",
     "iopub.status.idle": "2024-12-07T21:37:05.106164Z",
     "shell.execute_reply": "2024-12-07T21:37:05.105478Z",
     "shell.execute_reply.started": "2024-12-07T21:37:03.772739Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:640: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce0fbaf34364992801d3295746ec362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfaaee30dbda4310bdc9d1c3b82059d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac4fdd8628147a1b46ded7b4b1e2e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/449 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "max_tok_length = 128\n",
    "checkpoint = \"ajibawa-2023/Code-Llama-3-8B\" #\"codellama/CodeLlama-7b-hf\" #\"meta-llama/Llama-2-7b-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    checkpoint, use_auth_token=True,\n",
    "    padding=True,\n",
    "    pad_to_multiple_of=8,\n",
    "    truncation=True,\n",
    "    max_tok_len=max_tok_length,\n",
    "    padding_side='left',\n",
    "    )\n",
    "tokenizer.pad_token = \"[PAD]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:37:07.091930Z",
     "iopub.status.busy": "2024-12-07T21:37:07.091587Z",
     "iopub.status.idle": "2024-12-07T21:37:07.096409Z",
     "shell.execute_reply": "2024-12-07T21:37:07.095499Z",
     "shell.execute_reply.started": "2024-12-07T21:37:07.091901Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_function(sample):\n",
    "    model_inputs = tokenizer(\n",
    "        sample[\"source_text\"], \n",
    "        text_target = sample[\"dest_text\"],\n",
    "        )\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:37:09.460108Z",
     "iopub.status.busy": "2024-12-07T21:37:09.459760Z",
     "iopub.status.idle": "2024-12-07T21:37:16.801586Z",
     "shell.execute_reply": "2024-12-07T21:37:16.800800Z",
     "shell.execute_reply.started": "2024-12-07T21:37:09.460077Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977edb4968c942398e202361104cd969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4b7bab8f414f14aec12e219fbf4c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/477 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3390b7c10444cca7d2c554cdcd9afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/890 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds = ds.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T17:11:08.683636Z",
     "iopub.status.busy": "2024-12-06T17:11:08.682837Z",
     "iopub.status.idle": "2024-12-06T17:11:08.689314Z",
     "shell.execute_reply": "2024-12-06T17:11:08.688531Z",
     "shell.execute_reply.started": "2024-12-06T17:11:08.683601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source_text', 'dest_text', 'dest_lang'],\n",
       "        num_rows: 9308\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['source_text', 'dest_text', 'dest_lang'],\n",
       "        num_rows: 477\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source_text', 'dest_text', 'dest_lang'],\n",
       "        num_rows: 890\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:37:16.803233Z",
     "iopub.status.busy": "2024-12-07T21:37:16.802943Z",
     "iopub.status.idle": "2024-12-07T21:37:19.976102Z",
     "shell.execute_reply": "2024-12-07T21:37:19.975212Z",
     "shell.execute_reply.started": "2024-12-07T21:37:16.803205Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a4f6baa68343689f68823cc153bcb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Discarding source and target sentences with more than 128 tokens:   0%|          | 0/9308 [00:00<?, ? examples…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156d357676e444f0ad4ee62c39964dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Discarding source and target sentences with more than 128 tokens:   0%|          | 0/477 [00:00<?, ? examples/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5ab5e6fc3143c690f3d7cb91092dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Discarding source and target sentences with more than 128 tokens:   0%|          | 0/890 [00:00<?, ? examples/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds = tokenized_ds.filter(lambda x: len(x[\"input_ids\"]) <= max_tok_length and len(x[\"labels\"]) <= max_tok_length , desc=f\"Discarding source and target sentences with more than {max_tok_length} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T11:51:22.549875Z",
     "iopub.status.busy": "2024-12-07T11:51:22.549625Z",
     "iopub.status.idle": "2024-12-07T11:51:22.555739Z",
     "shell.execute_reply": "2024-12-07T11:51:22.554889Z",
     "shell.execute_reply.started": "2024-12-07T11:51:22.549851Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source_text', 'dest_text', 'dest_lang', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1079\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['source_text', 'dest_text', 'dest_lang', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 56\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source_text', 'dest_text', 'dest_lang', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 133\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:37:19.977663Z",
     "iopub.status.busy": "2024-12-07T21:37:19.977344Z",
     "iopub.status.idle": "2024-12-07T21:37:20.637915Z",
     "shell.execute_reply": "2024-12-07T21:37:20.636874Z",
     "shell.execute_reply.started": "2024-12-07T21:37:19.977635Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'length'}>]], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dic = []\n",
    "for sample in tokenized_ds['train']:\n",
    "    sample_length = len(sample['input_ids'])\n",
    "    dic.append(sample_length)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"length\":dic})\n",
    "df.hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:37:37.673623Z",
     "iopub.status.busy": "2024-12-07T21:37:37.673263Z",
     "iopub.status.idle": "2024-12-07T21:37:37.683812Z",
     "shell.execute_reply": "2024-12-07T21:37:37.682802Z",
     "shell.execute_reply.started": "2024-12-07T21:37:37.673590Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "src = \"py\"\n",
    "tgt = \"cpp\"\n",
    "task_prefix = f\"Translate from {src} to {tgt}:\\n\"\n",
    "s = \"\"\n",
    "\n",
    "\n",
    "tokenizer.pad_token_id = 128002 \n",
    "\n",
    "prefix_tok_len = len(tokenizer.encode(f\"{task_prefix}{src}: {s} = {tgt}: \"))\n",
    "max_tok_len = prefix_tok_len\n",
    "# Adding 2 for new line in target sentence and eos_token_id token\n",
    "max_tok_len += 2 * max_tok_length + 2\n",
    "\n",
    "\n",
    "def preprocess4training_function(sample):\n",
    "    \n",
    "    sample_size = len(sample[\"source_text\"])\n",
    "\n",
    "    # Creating the prompt with the task description for each source sentence\n",
    "    inputs  = [f\"{task_prefix}{src}: {s} = {tgt}: \" for s in sample[\"source_text\"]]\n",
    "\n",
    "    # Appending new line after each sample in the batch\n",
    "    targets = [f\"{s}\\n\" for s in sample[\"dest_text\"]]\n",
    "\n",
    "    # Applying the Llama2 tokenizer to the inputs and targets \n",
    "    # to obtain \"input_ids\" (token_ids) and \"attention mask\" \n",
    "    model_inputs = tokenizer(inputs)\n",
    "    labels = tokenizer(targets)\n",
    "    \n",
    "    # Each input is appended with its target \n",
    "    # Each target is prepended with as many special token id (-100) as the original input length\n",
    "    # Both input and target (label) has the same max_tok_len\n",
    "    # Attention mask is all 1s \n",
    "    for i in range(sample_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        label_input_ids = labels[\"input_ids\"][i] + [tokenizer.eos_token_id]\n",
    "        model_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n",
    "        labels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n",
    "\n",
    "    # Each input is applied left padding up to max_tok_len\n",
    "    # Attention mask is 0 for padding\n",
    "    # Each target (label) is left filled with special token id (-100)\n",
    "    # Finally inputs, attention_mask and targets (labels) are truncated to max_tok_len\n",
    "    for i in range(sample_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        label_input_ids = labels[\"input_ids\"][i]\n",
    "        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n",
    "            max_tok_len - len(sample_input_ids)\n",
    "        ) + sample_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [0] * (max_tok_len - len(sample_input_ids)) + model_inputs[\n",
    "            \"attention_mask\"\n",
    "        ][i]\n",
    "        labels[\"input_ids\"][i] = [-100] * (max_tok_len - len(sample_input_ids)) + label_input_ids\n",
    "        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_tok_len])\n",
    "        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_tok_len])\n",
    "        labels[\"input_ids\"][i] = torch.tensor(labels[\"input_ids\"][i][:max_tok_len])\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:37:25.644290Z",
     "iopub.status.busy": "2024-12-07T21:37:25.643377Z",
     "iopub.status.idle": "2024-12-07T21:37:25.648620Z",
     "shell.execute_reply": "2024-12-07T21:37:25.647727Z",
     "shell.execute_reply.started": "2024-12-07T21:37:25.644257Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess4test_function(sample):\n",
    "    inputs = [f\"{task_prefix}{src}: {s} = {tgt}: \" for s in sample[\"source_text\"]]\n",
    "    model_inputs = tokenizer(inputs,padding=True,)\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:37:40.870158Z",
     "iopub.status.busy": "2024-12-07T21:37:40.869814Z",
     "iopub.status.idle": "2024-12-07T21:37:41.909704Z",
     "shell.execute_reply": "2024-12-07T21:37:41.908484Z",
     "shell.execute_reply.started": "2024-12-07T21:37:40.870127Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d8fe6350dd4e33a104d9bc186599ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1402 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9dc214bcd34914b19c9c50a153c6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessed_train_dataset = tokenized_ds['train'].map(preprocess4training_function, batched=True)\n",
    "preprocessed_dev_dataset = tokenized_ds['validation'].map(preprocess4training_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:37:44.129788Z",
     "iopub.status.busy": "2024-12-07T21:37:44.129394Z",
     "iopub.status.idle": "2024-12-07T21:37:44.341920Z",
     "shell.execute_reply": "2024-12-07T21:37:44.340934Z",
     "shell.execute_reply.started": "2024-12-07T21:37:44.129758Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5f4b8e9bef40a5b0227593eeed152b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessed_test_dataset = tokenized_ds['test'].map(preprocess4test_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:37:46.485414Z",
     "iopub.status.busy": "2024-12-07T21:37:46.484413Z",
     "iopub.status.idle": "2024-12-07T21:37:46.490505Z",
     "shell.execute_reply": "2024-12-07T21:37:46.489643Z",
     "shell.execute_reply.started": "2024-12-07T21:37:46.485369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:37:48.321671Z",
     "iopub.status.busy": "2024-12-07T21:37:48.320978Z",
     "iopub.status.idle": "2024-12-07T21:45:15.949269Z",
     "shell.execute_reply": "2024-12-07T21:45:15.948308Z",
     "shell.execute_reply.started": "2024-12-07T21:37:48.321639Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32880842ffa4b2584fbcb1f5ec2072c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/716 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a353693a1c4d9ebfb4220219a3be82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7a689fc8724684851b8b7026bb8493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e001223606a44699b0dc69715540cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d28fdc6ba2ce4fdb9f43974d25b0e160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcf6225cb024ccea7b61e6b11249063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635ced63bc2a4cdc8365ab9fbbfc72ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eae29c13ce14c9fa083db530483b21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7eb046d1c140ff9936e786e7f39fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    checkpoint,\n",
    "    quantization_config=quantization_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:45:15.951579Z",
     "iopub.status.busy": "2024-12-07T21:45:15.950917Z",
     "iopub.status.idle": "2024-12-07T21:45:25.668336Z",
     "shell.execute_reply": "2024-12-07T21:45:25.667339Z",
     "shell.execute_reply.started": "2024-12-07T21:45:15.951538Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install peft==0.13 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:45:25.670149Z",
     "iopub.status.busy": "2024-12-07T21:45:25.669832Z",
     "iopub.status.idle": "2024-12-07T21:45:25.796709Z",
     "shell.execute_reply": "2024-12-07T21:45:25.795855Z",
     "shell.execute_reply.started": "2024-12-07T21:45:25.670120Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=False, gradient_checkpointing_kwargs={'use_reentrant':False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:45:25.799151Z",
     "iopub.status.busy": "2024-12-07T21:45:25.798812Z",
     "iopub.status.idle": "2024-12-07T21:45:25.803710Z",
     "shell.execute_reply": "2024-12-07T21:45:25.802806Z",
     "shell.execute_reply.started": "2024-12-07T21:45:25.799122Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    inference_mode=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:45:25.805743Z",
     "iopub.status.busy": "2024-12-07T21:45:25.805062Z",
     "iopub.status.idle": "2024-12-07T21:45:25.997918Z",
     "shell.execute_reply": "2024-12-07T21:45:25.996843Z",
     "shell.execute_reply.started": "2024-12-07T21:45:25.805701Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,815,744 || all params: 8,037,076,992 || trainable%: 0.0848\n"
     ]
    }
   ],
   "source": [
    "lora_model = get_peft_model(model, config)\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:45:25.999382Z",
     "iopub.status.busy": "2024-12-07T21:45:25.999081Z",
     "iopub.status.idle": "2024-12-07T21:45:27.273858Z",
     "shell.execute_reply": "2024-12-07T21:45:27.272910Z",
     "shell.execute_reply.started": "2024-12-07T21:45:25.999350Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False, pad_to_multiple_of=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:45:27.276410Z",
     "iopub.status.busy": "2024-12-07T21:45:27.275087Z",
     "iopub.status.idle": "2024-12-07T21:45:27.314351Z",
     "shell.execute_reply": "2024-12-07T21:45:27.313607Z",
     "shell.execute_reply.started": "2024-12-07T21:45:27.276370Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 1\n",
    "gradient_accumulation_steps = 8\n",
    "model_name = checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-py-to-cpp\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=3,\n",
    "    warmup_steps=100,\n",
    "    optim=\"adamw_bnb_8bit\",\n",
    "    prediction_loss_only=True,\n",
    "    gradient_accumulation_steps = gradient_accumulation_steps,\n",
    "    fp16=True,\n",
    "    group_by_length=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:45:27.315673Z",
     "iopub.status.busy": "2024-12-07T21:45:27.315382Z",
     "iopub.status.idle": "2024-12-07T21:45:29.347911Z",
     "shell.execute_reply": "2024-12-07T21:45:29.346885Z",
     "shell.execute_reply.started": "2024-12-07T21:45:27.315647Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:457: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    lora_model,\n",
    "    args,\n",
    "    train_dataset=preprocessed_train_dataset,\n",
    "    eval_dataset=preprocessed_dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:45:29.349318Z",
     "iopub.status.busy": "2024-12-07T21:45:29.349038Z",
     "iopub.status.idle": "2024-12-08T02:53:26.191941Z",
     "shell.execute_reply": "2024-12-08T02:53:26.191178Z",
     "shell.execute_reply.started": "2024-12-07T21:45:29.349292Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d1df7cd20643bbab4a0391dc0fc6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113341777778866, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241207_214938-v1taxvps</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hyperloopupv/huggingface/runs/v1taxvps' target=\"_blank\">atomic-armadillo-26</a></strong> to <a href='https://wandb.ai/hyperloopupv/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hyperloopupv/huggingface' target=\"_blank\">https://wandb.ai/hyperloopupv/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hyperloopupv/huggingface/runs/v1taxvps' target=\"_blank\">https://wandb.ai/hyperloopupv/huggingface/runs/v1taxvps</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='261' max='261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [261/261 5:02:43, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.546764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.462593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.454982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=261, training_loss=0.7500750077638589, metrics={'train_runtime': 18475.2845, 'train_samples_per_second': 0.228, 'train_steps_per_second': 0.014, 'total_flos': 2.7411404833161216e+16, 'train_loss': 0.7500750077638589, 'epoch': 2.98})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T02:53:26.194558Z",
     "iopub.status.busy": "2024-12-08T02:53:26.194269Z",
     "iopub.status.idle": "2024-12-08T02:53:30.091736Z",
     "shell.execute_reply": "2024-12-08T02:53:30.090871Z",
     "shell.execute_reply.started": "2024-12-08T02:53:26.194532Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60be08cc7eb74ce39fcae9862e090d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4510c57dc5de419a892325500af09d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9bb4c0c11f14c789cd0cdb3ccf62464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.bin:   0%|          | 0.00/27.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/hugo-albert/Code-Llama-3-8B-finetuned-py-to-cpp/commit/4ba6f0747235d2a2fa2a7fa485bfdf67b00b4b62', commit_message='Training complete', commit_description='', oid='4ba6f0747235d2a2fa2a7fa485bfdf67b00b4b62', pr_url=None, repo_url=RepoUrl('https://huggingface.co/hugo-albert/Code-Llama-3-8B-finetuned-py-to-cpp', endpoint='https://huggingface.co', repo_type='model', repo_id='hugo-albert/Code-Llama-3-8B-finetuned-py-to-cpp'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(commit_message=\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T02:53:30.093054Z",
     "iopub.status.busy": "2024-12-08T02:53:30.092781Z",
     "iopub.status.idle": "2024-12-08T02:53:30.155676Z",
     "shell.execute_reply": "2024-12-08T02:53:30.154820Z",
     "shell.execute_reply.started": "2024-12-08T02:53:30.093029Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 128001,\n",
      "  \"max_length\": 4096,\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_p\": 0.9,\n",
      "  \"transformers_version\": \"4.33.1\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "generation_config = GenerationConfig.from_pretrained(\n",
    "    checkpoint,\n",
    ")\n",
    "\n",
    "print(generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T02:53:30.157597Z",
     "iopub.status.busy": "2024-12-08T02:53:30.156810Z",
     "iopub.status.idle": "2024-12-08T02:53:30.274607Z",
     "shell.execute_reply": "2024-12-08T02:53:30.273876Z",
     "shell.execute_reply.started": "2024-12-08T02:53:30.157553Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03fe8b70e9c48839d8adaa181678252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batching examples:   0%|          | 0/157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_batch_size = 4\n",
    "batch_tokenized_test = preprocessed_test_dataset.batch(test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T02:53:30.275635Z",
     "iopub.status.busy": "2024-12-08T02:53:30.275410Z",
     "iopub.status.idle": "2024-12-08T03:32:18.060968Z",
     "shell.execute_reply": "2024-12-08T03:32:18.060289Z",
     "shell.execute_reply.started": "2024-12-08T02:53:30.275613Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "number_of_batches = len(batch_tokenized_test[\"input_ids\"])\n",
    "output_sequences = []\n",
    "for i in range(number_of_batches):\n",
    "    output_batch = lora_model.generate(\n",
    "        generation_config=generation_config, \n",
    "        input_ids=torch.tensor(batch_tokenized_test[\"input_ids\"][i]).cuda(), \n",
    "        attention_mask=torch.tensor(batch_tokenized_test[\"attention_mask\"][i]).cuda(), \n",
    "        max_length = max_tok_len, \n",
    "        num_beams=1, \n",
    "        do_sample=False,)\n",
    "    output_sequences.extend(output_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T03:32:18.062357Z",
     "iopub.status.busy": "2024-12-08T03:32:18.062056Z",
     "iopub.status.idle": "2024-12-08T03:32:30.595709Z",
     "shell.execute_reply": "2024-12-08T03:32:30.594807Z",
     "shell.execute_reply.started": "2024-12-08T03:32:18.062328Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install unbabel-comet --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T03:32:30.597653Z",
     "iopub.status.busy": "2024-12-08T03:32:30.597316Z",
     "iopub.status.idle": "2024-12-08T03:33:05.842851Z",
     "shell.execute_reply": "2024-12-08T03:33:05.842182Z",
     "shell.execute_reply.started": "2024-12-08T03:32:30.597622Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "comet = load(\"comet\")\n",
    "bleu = load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T03:33:05.844688Z",
     "iopub.status.busy": "2024-12-08T03:33:05.843934Z",
     "iopub.status.idle": "2024-12-08T03:33:05.851930Z",
     "shell.execute_reply": "2024-12-08T03:33:05.851124Z",
     "shell.execute_reply.started": "2024-12-08T03:33:05.844658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def compute_metrics(sample, output_sequences):\n",
    "    inputs = [f\"{task_prefix}{src}: {s} = {tgt}: \"  for s in sample[\"source_text\"]]\n",
    "    preds = tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n",
    "    #print(inputs)\n",
    "    #print(preds)\n",
    "    for i, (input,pred) in enumerate(zip(inputs,preds)):\n",
    "      pred = re.search(r'^.*\\n',pred.removeprefix(input).lstrip())\n",
    "      if pred is not None:\n",
    "        preds[i] = pred.group()[:-1]\n",
    "      else:\n",
    "        preds[i] = \"\"\n",
    "    #print(sample[\"source_text\"])\n",
    "    #print(sample[\"dest_text\"])\n",
    "    #print(preds)\n",
    "    resultcomet = comet.compute(sources = sample[\"source_text\"], predictions=preds, references=sample[\"dest_text\"])\n",
    "    resultbleu = bleu.compute(predictions=preds, references=sample[\"dest_text\"])\n",
    "    result = {\"bleu\": resultbleu[\"score\"], \"comet\": resultcomet[\"mean_score\"], \"comet_all\": resultcomet[\"scores\"]}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T03:33:05.853922Z",
     "iopub.status.busy": "2024-12-08T03:33:05.853238Z",
     "iopub.status.idle": "2024-12-08T03:33:18.661349Z",
     "shell.execute_reply": "2024-12-08T03:33:18.660279Z",
     "shell.execute_reply.started": "2024-12-08T03:33:05.853882Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.030584772861176963\n",
      "COMET score: 0.3682157149550262\n"
     ]
    }
   ],
   "source": [
    "result = compute_metrics(preprocessed_test_dataset,output_sequences)\n",
    "print(f'BLEU score: {result[\"bleu\"]}')\n",
    "print(f'COMET score: {result[\"comet\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T03:33:18.663602Z",
     "iopub.status.busy": "2024-12-08T03:33:18.662863Z",
     "iopub.status.idle": "2024-12-08T03:33:18.943088Z",
     "shell.execute_reply": "2024-12-08T03:33:18.942024Z",
     "shell.execute_reply.started": "2024-12-08T03:33:18.663560Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([119.,   4.,   0.,   5.,   4.,   3.,   1.,   3.,   5.,  13.]),\n",
       " array([0.22611144, 0.29714931, 0.36818718, 0.43922504, 0.51026291,\n",
       "        0.58130078, 0.65233865, 0.72337652, 0.79441438, 0.86545225,\n",
       "        0.93649012]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(result[\"comet_all\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T03:33:18.944558Z",
     "iopub.status.busy": "2024-12-08T03:33:18.944234Z",
     "iopub.status.idle": "2024-12-08T03:33:18.951271Z",
     "shell.execute_reply": "2024-12-08T03:33:18.950308Z",
     "shell.execute_reply.started": "2024-12-08T03:33:18.944527Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def check_translation(i):\n",
    "    print(f\"COMET of snippet {i}:\", result[\"comet_all\"][i])\n",
    "    print(\"REAL: \\n\", preprocessed_test_dataset[i][\"dest_text\"].replace(\"NEW_LINE\", \"\\n\"))\n",
    "    print(\"PRED: \\n\", tokenizer.batch_decode(output_sequences, skip_special_tokens=True)[i].replace(\"NEW_LINE\", \"\\n\").split(\"= cpp: \")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T03:33:18.952662Z",
     "iopub.status.busy": "2024-12-08T03:33:18.952354Z",
     "iopub.status.idle": "2024-12-08T03:33:18.988872Z",
     "shell.execute_reply": "2024-12-08T03:33:18.988078Z",
     "shell.execute_reply.started": "2024-12-08T03:33:18.952635Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMET of snippet 0: 0.2694762647151947\n",
      "REAL: \n",
      " void checkSolution ( int a , int b , int c ) { if ( a == c ) cout << \" Yes \" ; else cout << \" No \" ; }\n",
      "int main ( ) { int a = 2 , b = 0 , c = 2 ; checkSolution ( a , b , c ) ; return 0 ; }\n",
      "PRED: \n",
      " int checkSolution ( int a, int b, int c ) { if ( a == c ) cout << \" Yes \" ; else cout << \" No \" ; }\n",
      "int main ( ) { int a = 2, b = 0, c = 2 ; checkSolution ( a, b, c ) ; return 0 ; }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_translation(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T03:33:18.990084Z",
     "iopub.status.busy": "2024-12-08T03:33:18.989794Z",
     "iopub.status.idle": "2024-12-08T03:33:19.019953Z",
     "shell.execute_reply": "2024-12-08T03:33:19.019204Z",
     "shell.execute_reply.started": "2024-12-08T03:33:18.990038Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMET of snippet 1: 0.256288081407547\n",
      "REAL: \n",
      " void printKNumbers ( int N , int K ) {\n",
      "for ( int i = 0 ; i < K - 1 ; i ++ ) cout << 1 << \" ▁ \" ;\n",
      "cout << ( N - K + 1 ) ; }\n",
      "int main ( ) { int N = 10 , K = 3 ; printKNumbers ( N , K ) ; return 0 ; }\n",
      "PRED: \n",
      " int printKNumbers ( int N, int K ) {\n",
      "for ( int i = 0 ; i < K - 1 ; i ++ ) cout << 1 << \" ▁ \" ;\n",
      "cout << N - K + 1 ; return 0 ; }\n",
      "int main ( ) { int N = 10, K = 3 ; printKNumbers ( N, K ) ; return 0 ; }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_translation(1)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6219636,
     "sourceId": 10087360,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6228461,
     "sourceId": 10098879,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
